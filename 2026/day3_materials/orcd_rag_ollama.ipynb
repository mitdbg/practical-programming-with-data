{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7d4cd27d",
   "metadata": {},
   "source": [
    "**TODO:**\n",
    "- Clean up and add more instructions\n",
    "- Update to use satellite documents for class\n",
    "- Look into further ways we can play with metadata\n",
    "- Add structured data portion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7e3923b-98e3-421f-a9a1-d6ed09264e13",
   "metadata": {},
   "source": [
    "# Retrieval Augmented Generation with Unstructured Data using GPUs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f31fb1f8",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "Using the command line, create a new Conda environment using the `environment.yml` file:\n",
    "```bash\n",
    "module load miniforge\n",
    "conda env create -f environment.yml\n",
    "conda activate rag_ollama\n",
    "```\n",
    "\n",
    "Alternatively, install the necessary packages manually:\n",
    "\n",
    "```bash\n",
    "module load miniforge\n",
    "conda create -n rag_ollama jupyterlab langchain-ollama langchain-chroma langchain-community\n",
    "conda activate rag_ollama\n",
    "pip install \"unstructured[pdf]\"\n",
    "```\n",
    "\n",
    "Create a Jupyter kernel for your environment:\n",
    "```bash\n",
    "python -m ipykernel install --user --name rag_ollama\n",
    "```\n",
    "\n",
    "Connect this notebook to the Jupyter kernel you just created. You may need to disconnect from and reconnect to your Jupyter session.\n",
    "\n",
    "Run the setup script to start Ollama and download the embedding and language models:\n",
    "```bash\n",
    "sh start_ollama.sh\n",
    "```\n",
    "\n",
    "Import packages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "337f9305",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/secorey/orcd/scratch/.conda/envs/rag_ollama/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_ollama import OllamaEmbeddings, OllamaLLM\n",
    "from langchain_community.document_loaders import UnstructuredPDFLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain.agents.middleware import dynamic_prompt, ModelRequest\n",
    "from langchain.agents import create_agent\n",
    "import logging\n",
    "from IPython.display import Markdown, display"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3425058e",
   "metadata": {},
   "source": [
    "Set environment variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7156e55c",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"config.json\", \"r\") as f:\n",
    "    config = json.load(f)\n",
    "\n",
    "EMBEDDING_MODEL_NAME = config[\"embedding_model\"]\n",
    "LLM_NAME = config[\"llm\"]\n",
    "\n",
    "DOCS_PATH = os.path.join(os.getcwd(), \"docs\")\n",
    "VECTOR_STORE_PATH = os.path.join(os.getcwd(), \"vector_store\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87272f73",
   "metadata": {},
   "source": [
    "Initialize components:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7a55fbf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = OllamaEmbeddings(\n",
    "    model=EMBEDDING_MODEL_NAME\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57bef930",
   "metadata": {},
   "source": [
    "## Processing PDFs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "459b8f3f-1847-4bd8-87a9-098913b93e72",
   "metadata": {},
   "source": [
    "We have a set of PDFs that we would like to input into our RAG pipeline. We cannot do this directly, however. While PDFs are optimized for humans to read and comprehend, machines have a harder time. So, we must first process our documents so that they can be efficiently searched by a computer. We will do this in two steps:\n",
    "1. Extract the raw text from the PDFs\n",
    "2. Convert the text into vectors using an embedding model\n",
    "\n",
    "### Extracting Text from PDFs\n",
    "\n",
    "The `unstructured` software has a PDF loading tool that extracts text from PDFs and ignores images. This software uses the `pdfminer.six` Python package under the hood, which is very popular for reading PDFs using Python.\n",
    "\n",
    "*Note: `unstructured` has loaders for other file formats as well, such as Markdown or Word documents.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9fbbddc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mute pdfminer warnings globally\n",
    "logging.getLogger(\"pdfminer\").setLevel(logging.ERROR)\n",
    "logging.getLogger(\"pdfminer.pdffont\").setLevel(logging.ERROR)\n",
    "\n",
    "def load_documents(docs_path):\n",
    "    \"\"\"\n",
    "    Load documents from the specified directory recursively. Documents must be\n",
    "    in .pdf format.\n",
    "    \"\"\"\n",
    "\n",
    "    # Load the documents recursively:\n",
    "    documents = []\n",
    "    for file_name in os.listdir(docs_path):\n",
    "        file_path = os.path.join(docs_path, file_name)\n",
    "        if file_name.endswith('.pdf'):\n",
    "            loader = UnstructuredPDFLoader(file_path, languages=[\"eng\"])\n",
    "            doc = loader.load()\n",
    "            doc[0].metadata[\"source\"] = file_name\n",
    "            documents.extend(doc)\n",
    "        elif os.path.isdir(file_path):\n",
    "            documents.extend(load_documents(file_path))\n",
    "    return documents\n",
    "\n",
    "documents = load_documents(DOCS_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cd5496c",
   "metadata": {},
   "source": [
    "This creates a list of documents:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "56dfe2b5-dffb-4989-9887-34db59320da2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(metadata={'source': 'NewReno.pdf'}, page_content='Network Working Group S. Floyd Request for Comments: 3782 ICSI Obsoletes: 2582 T. Henderson Category: Standards Track Boeing A. Gurtov TeliaSonera April 2004\\n\\nThe NewReno Modification to TCP’s Fast Recovery Algorithm\\n\\nStatus of this Memo\\n\\nThis document specifies an Internet standards track protocol for the Internet community, and requests discussion and suggestions for improvements. Please refer to the current edition of the \"Internet Official Protocol Standards\" (STD 1) for the standardization state and status of this protocol. Distribution of this memo is unlimited.\\n\\nCopyright Notice\\n\\nCopyright (C) The Internet Society (2004). All Rights Reserved.\\n\\nAbstract\\n\\nThe purpose of this document is to advance NewReno TCP’s Fast Retransmit and Fast Recovery algorithms in RFC 2582 from Experimental to Standards Track status.\\n\\nThe main change in this document relative to RFC 2582 is to specify the Careful variant of NewReno’s Fast Retransmit and Fast Recovery algorithms. The base algorithm described in RFC 2582 did not attempt to avoid unnecessary multiple Fast Retransmits that can occur after a timeout. However, RFC 2582 also defined \"Careful\" and \"Less Careful\" variants that avoid these unnecessary Fast Retransmits, and recommended the Careful variant. This document specifies the previously-named \"Careful\" variant as the basic version of NewReno TCP.\\n\\nFloyd, et al. Standards Track [Page 1]\\n\\nRFC 3782 NewReno Modification to Fast Recovery Algorithm April 2004\\n\\n1. Introduction\\n\\nFor the typical implementation of the TCP Fast Recovery algorithm described in [RFC2581] (first implemented in the 1990 BSD Reno release, and referred to as the Reno algorithm in [FF96]), the TCP data sender only retransmits a packet after a retransmit timeout has occurred, or after three duplicate acknowledgements have arrived triggering the Fast Retransmit algorithm. A single retransmit timeout might result in the retransmission of several data packets, but each invocation of the Fast Retransmit algorithm in RFC 2581 leads to the retransmission of only a single data packet.\\n\\nProblems can arise, therefore, when multiple packets are dropped from a single window of data and the Fast Retransmit and Fast Recovery algorithms are invoked. In this case, if the SACK option is available, the TCP sender has the information to make intelligent decisions about which packets to retransmit and which packets not to retransmit during Fast Recovery. This document applies only for TCP connections that are unable to use the TCP Selective Acknowledgement (SACK) option, either because the option is not locally supported or because the TCP peer did not indicate a willingness to use SACK.\\n\\nIn the absence of SACK, there is little information available to the TCP sender in making retransmission decisions during Fast Recovery. From the three duplicate acknowledgements, the sender infers a packet loss, and retransmits the indicated packet. After this, the data sender could receive additional duplicate acknowledgements, as the data receiver acknowledges additional data packets that were already in flight when the sender entered Fast Retransmit.\\n\\nIn the case of multiple packets dropped from a single window of data, the first new information available to the sender comes when the sender receives an acknowledgement for the retransmitted packet (that is, the packet retransmitted when Fast Retransmit was first entered). If there is a single packet drop and no reordering, then the acknowledgement for this packet will acknowledge all of the packets transmitted before Fast Retransmit was entered. However, if there are multiple packet drops, then the acknowledgement for the retransmitted packet will acknowledge some but not all of the packets transmitted before the Fast Retransmit. We call this acknowledgement a partial acknowledgment.\\n\\nAlong with several other suggestions, [Hoe95] suggested that during Fast Recovery the TCP data sender responds to a partial acknowledgment by inferring that the next in-sequence packet has been lost, and retransmitting that packet. This document describes a modification to the Fast Recovery algorithm in RFC 2581 that incorporates a response to partial acknowledgements received during\\n\\nFloyd, et al. Standards Track [Page 2]\\n\\nRFC 3782 NewReno Modification to Fast Recovery Algorithm April 2004\\n\\nFast Recovery. We call this modified Fast Recovery algorithm NewReno, because it is a slight but significant variation of the basic Reno algorithm in RFC 2581. This document does not discuss the other suggestions in [Hoe95] and [Hoe96], such as a change to the ssthresh parameter during Slow-Start, or the proposal to send a new packet for every two duplicate acknowledgements during Fast Recovery. The version of NewReno in this document also draws on other discussions of NewReno in the literature [LM97, Hen98].\\n\\nWe do not claim that the NewReno version of Fast Recovery described here is an optimal modification of Fast Recovery for responding to partial acknowledgements, for TCP connections that are unable to use SACK. Based on our experiences with the NewReno modification in the NS simulator [NS] and with numerous implementations of NewReno, we believe that this modification improves the performance of the Fast Retransmit and Fast Recovery algorithms in a wide variety of scenarios.\\n\\n2. Terminology and Definitions\\n\\nIn this document, the key words \"MUST\", \"MUST NOT\", \"REQUIRED\", \"SHALL\", \"SHALL NOT\", \"SHOULD\", \"SHOULD NOT\", \"RECOMMENDED\", \"MAY\", and \"OPTIONAL\" are to be interpreted as described in BCP 14, RFC 2119 [RFC2119]. This RFC indicates requirement levels for compliant TCP implementations implementing the NewReno Fast Retransmit and Fast Recovery algorithms described in this document.\\n\\nThis document assumes that the reader is familiar with the terms SENDER MAXIMUM SEGMENT SIZE (SMSS), CONGESTION WINDOW (cwnd), and FLIGHT SIZE (FlightSize) defined in [RFC2581]. FLIGHT SIZE is defined as in [RFC2581] as follows:\\n\\nFLIGHT SIZE: The amount of data that has been sent but not yet acknowledged.\\n\\n3. The Fast Retransmit and Fast Recovery Algorithms in NewReno\\n\\nThe standard implementation of the Fast Retransmit and Fast Recovery algorithms is given in [RFC2581]. This section specifies the basic NewReno algorithm. Sections 4 through 6 describe some optional variants, and the motivations behind them, that an implementor may want to consider when tuning performance for certain network scenarios. Sections 7 and 8 provide some guidance to implementors based on experience with NewReno implementations.\\n\\nThe NewReno modification concerns the Fast Recovery procedure that begins when three duplicate ACKs are received and ends when either a retransmission timeout occurs or an ACK arrives that acknowledges all\\n\\nFloyd, et al. Standards Track [Page 3]\\n\\nRFC 3782 NewReno Modification to Fast Recovery Algorithm April 2004\\n\\nof the data up to and including the data that was outstanding when the Fast Recovery procedure began.\\n\\nThe NewReno algorithm specified in this document differs from the implementation in [RFC2581] in the introduction of the variable \"recover\" in step 1, in the response to a partial or new acknowledgement in step 5, and in modifications to step 1 and the addition of step 6 for avoiding multiple Fast Retransmits caused by the retransmission of packets already received by the receiver.\\n\\nThe algorithm specified in this document uses a variable \"recover\", whose initial value is the initial send sequence number.\\n\\n1) Three duplicate ACKs: When the third duplicate ACK is received and the sender is not already in the Fast Recovery procedure, check to see if the Cumulative Acknowledgement field covers more than \"recover\". If so, go to Step 1A. Otherwise, go to Step 1B. 1A) Invoking Fast Retransmit: If so, then set ssthresh to no more than the value given in equation 1 below. (This is equation 3 from [RFC2581]).\\n\\nssthresh = max (FlightSize / 2, 2*SMSS) (1)\\n\\nIn addition, record the highest sequence number transmitted in the variable \"recover\", and go to Step 2.\\n\\n1B) Not invoking Fast Retransmit: Do not enter the Fast Retransmit and Fast Recovery procedure. In particular, do not change ssthresh, do not go to Step 2 to retransmit the \"lost\" segment, and do not execute Step 3 upon subsequent duplicate ACKs.\\n\\n2) Entering Fast Retransmit: Retransmit the lost segment and set cwnd to ssthresh plus 3*SMSS. This artificially \"inflates\" the congestion window by the number of segments (three) that have left the network and the receiver has buffered.\\n\\n3) Fast Recovery: For each additional duplicate ACK received while in Fast Recovery, increment cwnd by SMSS. This artificially inflates the congestion window in order to reflect the additional segment that has left the network.\\n\\nFloyd, et al. Standards Track [Page 4]\\n\\nRFC 3782 NewReno Modification to Fast Recovery Algorithm April 2004\\n\\n4) Fast Recovery, continued: Transmit a segment, if allowed by the new value of cwnd and the receiver’s advertised window.\\n\\n5) When an ACK arrives that acknowledges new data, this ACK could be the acknowledgment elicited by the retransmission from step 2, or elicited by a later retransmission.\\n\\nFull acknowledgements: If this ACK acknowledges all of the data up to and including \"recover\", then the ACK acknowledges all the intermediate segments sent between the original transmission of the lost segment and the receipt of the third duplicate ACK. Set cwnd to either (1) min (ssthresh, FlightSize + SMSS) or (2) ssthresh, where ssthresh is the value set in step 1; this is termed \"deflating\" the window. (We note that \"FlightSize\" in step 1 referred to the amount of data outstanding in step 1, when Fast Recovery was entered, while \"FlightSize\" in step 5 refers to the amount of data outstanding in step 5, when Fast Recovery is exited.) If the second option is selected, the implementation is encouraged to take measures to avoid a possible burst of data, in case the amount of data outstanding in the network is much less than the new congestion window allows. A simple mechanism is to limit the number of data packets that can be sent in response to a single acknowledgement; this is known as \"maxburst_\" in the NS simulator. Exit the Fast Recovery procedure.\\n\\nPartial acknowledgements: If this ACK does *not* acknowledge all of the data up to and including \"recover\", then this is a partial ACK. In this case, retransmit the first unacknowledged segment. Deflate the congestion window by the amount of new data acknowledged by the cumulative acknowledgement field. If the partial ACK acknowledges at least one SMSS of new data, then add back SMSS bytes to the congestion window. As in Step 3, this artificially inflates the congestion window in order to reflect the additional segment that has left the network. Send a new segment if permitted by the new value of cwnd. This \"partial window deflation\" attempts to ensure that, when Fast Recovery eventually ends, approximately ssthresh amount of data will be outstanding in the network. Do not exit the Fast Recovery procedure (i.e., if any duplicate ACKs subsequently arrive, execute Steps 3 and 4 above).\\n\\nFor the first partial ACK that arrives during Fast Recovery, also reset the retransmit timer. Timer management is discussed in more detail in Section 4.\\n\\nFloyd, et al. Standards Track [Page 5]\\n\\nRFC 3782 NewReno Modification to Fast Recovery Algorithm April 2004\\n\\n6) Retransmit timeouts: After a retransmit timeout, record the highest sequence number transmitted in the variable \"recover\" and exit the Fast Recovery procedure if applicable. Step 1 specifies a check that the Cumulative Acknowledgement field covers more than \"recover\". Because the acknowledgement field contains the sequence number that the sender next expects to receive, the acknowledgement \"ack_number\" covers more than \"recover\" when:\\n\\nack_number - 1 > recover;\\n\\ni.e., at least one byte more of data is acknowledged beyond the highest byte that was outstanding when Fast Retransmit was last entered.\\n\\nNote that in Step 5, the congestion window is deflated after a partial acknowledgement is received. The congestion window was likely to have been inflated considerably when the partial acknowledgement was received. In addition, depending on the original pattern of packet losses, the partial acknowledgement might acknowledge nearly a window of data. In this case, if the congestion window was not deflated, the data sender might be able to send nearly a window of data back-to-back.\\n\\nThis document does not specify the sender’s response to duplicate ACKs when the Fast Retransmit/Fast Recovery algorithm is not invoked. This is addressed in other documents, such as those describing the Limited Transmit procedure [RFC3042]. This document also does not address issues of adjusting the duplicate acknowledgement threshold, but assumes the threshold specified in the IETF standards; the current standard is RFC 2581, which specifies a threshold of three duplicate acknowledgements.\\n\\nAs a final note, we would observe that in the absence of the SACK option, the data sender is working from limited information. When the issue of recovery from multiple dropped packets from a single window of data is of particular importance, the best alternative would be to use the SACK option.\\n\\n4. Resetting the Retransmit Timer in Response to Partial Acknowledgements\\n\\nOne possible variant to the response to partial acknowledgements specified in Section 3 concerns when to reset the retransmit timer after a partial acknowledgement. The algorithm in Section 3, Step 5, resets the retransmit timer only after the first partial ACK. In this case, if a large number of packets were dropped from a window of\\n\\nFloyd, et al. Standards Track [Page 6]\\n\\nRFC 3782 NewReno Modification to Fast Recovery Algorithm April 2004\\n\\ndata, the TCP data sender’s retransmit timer will ultimately expire, and the TCP data sender will invoke Slow-Start. (This is illustrated on page 12 of [F98].) We call this the Impatient variant of NewReno. We note that the Impatient variant in Section 3 doesn’t follow the recommended algorithm in RFC 2988 of restarting the retransmit timer after every packet transmission or retransmission [RFC2988, Step 5.1].\\n\\nIn contrast, the NewReno simulations in [FF96] illustrate the algorithm described above with the modification that the retransmit timer is reset after each partial acknowledgement. We call this the Slow-but-Steady variant of NewReno. In this case, for a window with a large number of packet drops, the TCP data sender retransmits at most one packet per roundtrip time. (This behavior is illustrated in the New-Reno TCP simulation of Figure 5 in [FF96], and on page 11 of [F98]).\\n\\nWhen N packets have been dropped from a window of data for a large value of N, the Slow-but-Steady variant can remain in Fast Recovery for N round-trip times, retransmitting one more dropped packet each round-trip time; for these scenarios, the Impatient variant gives a faster recovery and better performance. The tests \"ns test-suite- newreno.tcl impatient1\" and \"ns test-suite-newreno.tcl slow1\" in the NS simulator illustrate such a scenario, where the Impatient variant performs better than the Slow-but-Steady variant. The Impatient variant can be particularly important for TCP connections with large congestion windows, as illustrated by the tests \"ns test-suite- newreno.tcl impatient4\" and \"ns test-suite-newreno.tcl slow4\" in the NS simulator.\\n\\nOne can also construct scenarios where the Slow-but-Steady variant gives better performance than the Impatient variant. As an example, this occurs when only a small number of packets are dropped, the RTO is sufficiently small that the retransmit timer expires, and performance would have been better without a retransmit timeout. The tests \"ns test-suite-newreno.tcl impatient2\" and \"ns test-suite- newreno.tcl slow2\" in the NS simulator illustrate such a scenario.\\n\\nThe Slow-but-Steady variant can also achieve higher goodput than the Impatient variant, by avoiding unnecessary retransmissions. This could be of special interest for cellular links, where every transmission costs battery power and money. The tests \"ns test- suite-newreno.tcl impatient3\" and \"ns test-suite-newreno.tcl slow3\" in the NS simulator illustrate such a scenario. The Slow-but-Steady variant can also be more robust to delay variation in the network, where a delay spike might force the Impatient variant into a timeout and go-back-N recovery.\\n\\nFloyd, et al. Standards Track [Page 7]\\n\\nRFC 3782 NewReno Modification to Fast Recovery Algorithm April 2004\\n\\nNeither of the two variants discussed above are optimal. Our recommendation is for the Impatient variant, as specified in Section 3 of this document, because of the poor performance of the Slow-but- Steady variant for TCP connections with large congestion windows.\\n\\nOne possibility for a more optimal algorithm would be one that recovered from multiple packet drops as quickly as does slow-start, while resetting the retransmit timers after each partial acknowledgement, as described in the section below. We note, however, that there is a limitation to the potential performance in this case in the absence of the SACK option.\\n\\n5. Retransmissions after a Partial Acknowledgement\\n\\nOne possible variant to the response to partial acknowledgements specified in Section 3 would be to retransmit more than one packet after each partial acknowledgement, and to reset the retransmit timer after each retransmission. The algorithm specified in Section 3 retransmits a single packet after each partial acknowledgement. This is the most conservative alternative, in that it is the least likely to result in an unnecessarily-retransmitted packet. A variant that would recover faster from a window with many packet drops would be to effectively Slow-Start, retransmitting two packets after each partial acknowledgement. Such an approach would take less than N roundtrip times to recover from N losses [Hoe96]. However, in the absence of SACK, recovering as quickly as slow-start introduces the likelihood of unnecessarily retransmitting packets, and this could significantly complicate the recovery mechanisms.\\n\\nWe note that the response to partial acknowledgements specified in Section 3 of this document and in RFC 2582 differs from the response in [FF96], even though both approaches only retransmit one packet in response to a partial acknowledgement. Step 5 of Section 3 specifies that the TCP sender responds to a partial ACK by deflating the congestion window by the amount of new data acknowledged, adding back SMSS bytes if the partial ACK acknowledges at least SMSS bytes of new data, and sending a new segment if permitted by the new value of cwnd. Thus, only one previously-sent packet is retransmitted in response to each partial acknowledgement, but additional new packets might be transmitted as well, depending on the amount of new data acknowledged by the partial acknowledgement. In contrast, the variant of NewReno illustrated in [FF96] simply set the congestion window to ssthresh when a partial acknowledgement was received. The approach in [FF96] is more conservative, and does not attempt to accurately track the actual number of outstanding packets after a partial acknowledgement is received. While either of these approaches gives acceptable performance, the variant specified in Section 3 recovers more smoothly when multiple packets are dropped\\n\\nFloyd, et al. Standards Track [Page 8]\\n\\nRFC 3782 NewReno Modification to Fast Recovery Algorithm April 2004\\n\\nfrom a window of data. (The [FF96] behavior can be seen in the NS simulator by setting the variable \"partial_window_deflation_\" for \"Agent/TCP/Newreno\" to 0; the behavior specified in Section 3 is achieved by setting \"partial_window_deflation_\" to 1.)\\n\\n6. Avoiding Multiple Fast Retransmits\\n\\nThis section describes the motivation for the sender’s state variable \"recover\", and discusses possible heuristics for distinguishing between a retransmitted packet that was dropped, and three duplicate acknowledgements from the unnecessary retransmission of three packets.\\n\\nIn the absence of the SACK option or timestamps, a duplicate acknowledgement carries no information to identify the data packet or packets at the TCP data receiver that triggered that duplicate acknowledgement. In this case, the TCP data sender is unable to distinguish between a duplicate acknowledgement that results from a lost or delayed data packet, and a duplicate acknowledgement that results from the sender’s unnecessary retransmission of a data packet that had already been received at the TCP data receiver. Because of this, with the Retransmit and Fast Recovery algorithms in Reno TCP, multiple segment losses from a single window of data can sometimes result in unnecessary multiple Fast Retransmits (and multiple reductions of the congestion window) [F94].\\n\\nWith the Fast Retransmit and Fast Recovery algorithms in Reno TCP, the performance problems caused by multiple Fast Retransmits are relatively minor compared to the potential problems with Tahoe TCP, which does not implement Fast Recovery. Nevertheless, unnecessary Fast Retransmits can occur with Reno TCP unless some explicit mechanism is added to avoid this, such as the use of the \"recover\" variable. (This modification is called \"bugfix\" in [F98], and is illustrated on pages 7 and 9 of that document. Unnecessary Fast Retransmits for Reno without \"bugfix\" is illustrated on page 6 of [F98].)\\n\\nSection 3 of [RFC2582] defined a default variant of NewReno TCP that did not use the variable \"recover\", and did not check if duplicate ACKs cover the variable \"recover\" before invoking Fast Retransmit. With this default variant from RFC 2582, the problem of multiple Fast Retransmits from a single window of data can occur after a Retransmit Timeout (as in page 8 of [F98]) or in scenarios with reordering (as in the validation test \"./test-all-newreno newreno5_noBF\" in directory \"tcl/test\" of the NS simulator. This gives performance similar to that on page 8 of [F03].) RFC 2582 also defined Careful and Less Careful variants of the NewReno algorithm, and recommended the Careful variant.\\n\\nFloyd, et al. Standards Track [Page 9]\\n\\nRFC 3782 NewReno Modification to Fast Recovery Algorithm April 2004\\n\\nThe algorithm specified in Section 3 of this document corresponds to the Careful variant of NewReno TCP from RFC 2582, and eliminates the problem of multiple Fast Retransmits. This algorithm uses the variable \"recover\", whose initial value is the initial send sequence number. After each retransmit timeout, the highest sequence number transmitted so far is recorded in the variable \"recover\".\\n\\nIf, after a retransmit timeout, the TCP data sender retransmits three consecutive packets that have already been received by the data receiver, then the TCP data sender will receive three duplicate acknowledgements that do not cover more than \"recover\". In this case, the duplicate acknowledgements are not an indication of a new instance of congestion. They are simply an indication that the sender has unnecessarily retransmitted at least three packets.\\n\\nHowever, when a retransmitted packet is itself dropped, the sender can also receive three duplicate acknowledgements that do not cover more than \"recover\". In this case, the sender would have been better off if it had initiated Fast Retransmit. For a TCP that implements the algorithm specified in Section 3 of this document, the sender does not infer a packet drop from duplicate acknowledgements in this scenario. As always, the retransmit timer is the backup mechanism for inferring packet loss in this case.\\n\\nThere are several heuristics, based on timestamps or on the amount of advancement of the cumulative acknowledgement field, that allow the sender to distinguish, in some cases, between three duplicate acknowledgements following a retransmitted packet that was dropped, and three duplicate acknowledgements from the unnecessary retransmission of three packets [Gur03, GF04]. The TCP sender MAY use such a heuristic to decide to invoke a Fast Retransmit in some cases, even when the three duplicate acknowledgements do not cover more than \"recover\".\\n\\nFor example, when three duplicate acknowledgements are caused by the unnecessary retransmission of three packets, this is likely to be accompanied by the cumulative acknowledgement field advancing by at least four segments. Similarly, a heuristic based on timestamps uses the fact that when there is a hole in the sequence space, the timestamp echoed in the duplicate acknowledgement is the timestamp of the most recent data packet that advanced the cumulative acknowledgement field [RFC1323]. If timestamps are used, and the sender stores the timestamp of the last acknowledged segment, then the timestamp echoed by duplicate acknowledgements can be used to distinguish between a retransmitted packet that was dropped and three duplicate acknowledgements from the unnecessary retransmission of three packets. The heuristics are illustrated in the NS simulator in the validation test \"./test-all-newreno\".\\n\\nFloyd, et al. Standards Track [Page 10]\\n\\nRFC 3782 NewReno Modification to Fast Recovery Algorithm April 2004\\n\\n6.1. ACK Heuristic\\n\\nIf the ACK-based heuristic is used, then following the advancement of the cumulative acknowledgement field, the sender stores the value of the previous cumulative acknowledgement as prev_highest_ack, and stores the latest cumulative ACK as highest_ack. In addition, the following step is performed if Step 1 in Section 3 fails, before proceeding to Step 1B.\\n\\n1*) If the Cumulative Acknowledgement field didn’t cover more than \"recover\", check to see if the congestion window is greater than SMSS bytes and the difference between highest_ack and prev_highest_ack is at most 4*SMSS bytes. If true, duplicate ACKs indicate a lost segment (proceed to Step 1A in Section 3). Otherwise, duplicate ACKs likely result from unnecessary retransmissions (proceed to Step 1B in Section 3).\\n\\nThe congestion window check serves to protect against fast retransmit immediately after a retransmit timeout, similar to the \"exitFastRetrans_\" variable in NS. Examples of applying the ACK heuristic are in validation tests \"./test-all-newreno newreno_rto_loss_ack\" and \"./test-all-newreno newreno_rto_dup_ack\" in directory \"tcl/test\" of the NS simulator.\\n\\nIf several ACKs are lost, the sender can see a jump in the cumulative ACK of more than three segments, and the heuristic can fail. A validation test for this scenario is \"./test-all-newreno newreno_rto_loss_ackf\". RFC 2581 recommends that a receiver should send duplicate ACKs for every out-of-order data packet, such as a data packet received during Fast Recovery. The ACK heuristic is more likely to fail if the receiver does not follow this advice, because then a smaller number of ACK losses are needed to produce a sufficient jump in the cumulative ACK.\\n\\n6.2. Timestamp Heuristic\\n\\nIf this heuristic is used, the sender stores the timestamp of the last acknowledged segment. In addition, the second paragraph of step 1 in Section 3 is replaced as follows:\\n\\n1**) If the Cumulative Acknowledgement field didn’t cover more than \"recover\", check to see if the echoed timestamp in the last non-duplicate acknowledgment equals the stored timestamp. If true, duplicate ACKs indicate a lost segment (proceed to Step 1A in Section 3). Otherwise, duplicate ACKs likely result from unnecessary retransmissions (proceed to Step 1B in Section 3).\\n\\nFloyd, et al. Standards Track [Page 11]\\n\\nRFC 3782 NewReno Modification to Fast Recovery Algorithm April 2004\\n\\nExamples of applying the timestamp heuristic are in validation tests \"./test-all-newreno newreno_rto_loss_tsh\" and \"./test-all-newreno newreno_rto_dup_tsh\". The timestamp heuristic works correctly, both when the receiver echoes timestamps as specified by [RFC1323], and by its revision attempts. However, if the receiver arbitrarily echoes timestamps, the heuristic can fail. The heuristic can also fail if a timeout was spurious and returning ACKs are not from retransmitted segments. This can be prevented by detection algorithms such as [RFC3522].\\n\\n7. Implementation Issues for the Data Receiver\\n\\n[RFC2581] specifies that \"Out-of-order data segments SHOULD be acknowledged immediately, in order to accelerate loss recovery.\" Neal Cardwell has noted that some data receivers do not send an immediate acknowledgement when they send a partial acknowledgment, but instead wait first for their delayed acknowledgement timer to expire [C98]. As [C98] notes, this severely limits the potential benefit of NewReno by delaying the receipt of the partial acknowledgement at the data sender. Echoing RFC 2581, our recommendation is that the data receiver send an immediate acknowledgement for an out-of-order segment, even when that out-of- order segment fills a hole in the buffer.\\n\\n8. Implementation Issues for the Data Sender\\n\\nIn Section 3, Step 5 above, it is noted that implementations should take measures to avoid a possible burst of data when leaving Fast Recovery, in case the amount of new data that the sender is eligible to send due to the new value of the congestion window is large. This can arise during NewReno when ACKs are lost or treated as pure window updates, thereby causing the sender to underestimate the number of new segments that can be sent during the recovery procedure. Specifically, bursts can occur when the FlightSize is much less than the new congestion window when exiting from Fast Recovery. One simple mechanism to avoid a burst of data when leaving Fast Recovery is to limit the number of data packets that can be sent in response to a single acknowledgment. (This is known as \"maxburst_\" in the ns simulator.) Other possible mechanisms for avoiding bursts include rate-based pacing, or setting the slow-start threshold to the resultant congestion window and then resetting the congestion window to FlightSize. A recommendation on the general mechanism to avoid excessively bursty sending patterns is outside the scope of this document.\\n\\nAn implementation may want to use a separate flag to record whether or not it is presently in the Fast Recovery procedure. The use of the value of the duplicate acknowledgment counter for this purpose is\\n\\nFloyd, et al. Standards Track [Page 12]\\n\\nRFC 3782 NewReno Modification to Fast Recovery Algorithm April 2004\\n\\nnot reliable because it can be reset upon window updates and out-of- order acknowledgments.\\n\\nWhen not in Fast Recovery, the value of the state variable \"recover\" should be pulled along with the value of the state variable for acknowledgments (typically, \"snd_una\") so that, when large amounts of data have been sent and acked, the sequence space does not wrap and falsely indicate that Fast Recovery should not be entered (Section 3, step 1, last paragraph).\\n\\nIt is important for the sender to respond correctly to duplicate ACKs received when the sender is no longer in Fast Recovery (e.g., because of a Retransmit Timeout). The Limited Transmit procedure [RFC3042] describes possible responses to the first and second duplicate acknowledgements. When three or more duplicate acknowledgements are received, the Cumulative Acknowledgement field doesn’t cover more than \"recover\", and a new Fast Recovery is not invoked, it is important that the sender not execute the Fast Recovery steps (3) and (4) in Section 3. Otherwise, the sender could end up in a chain of spurious timeouts. We mention this only because several NewReno implementations had this bug, including the implementation in the NS simulator. (This bug in the NS simulator was fixed in July 2003, with the variable \"exitFastRetrans_\".)\\n\\n9. Simulations\\n\\nSimulations with NewReno are illustrated with the validation test \"tcl/test/test-all-newreno\" in the NS simulator. The command \"../../ns test-suite-newreno.tcl reno\" shows a simulation with Reno TCP, illustrating the data sender’s lack of response to a partial acknowledgement. In contrast, the command \"../../ns test-suite- newreno.tcl newreno_B\" shows a simulation with the same scenario using the NewReno algorithms described in this paper.\\n\\n10. Comparisons between Reno and NewReno TCP\\n\\nAs we stated in the introduction, we believe that the NewReno modification described in this document improves the performance of the Fast Retransmit and Fast Recovery algorithms of Reno TCP in a wide variety of scenarios. This has been discussed in some depth in [FF96], which illustrates Reno TCP’s poor performance when multiple packets are dropped from a window of data and also illustrates NewReno TCP’s good performance in that scenario.\\n\\nWe do, however, know of one scenario where Reno TCP gives better performance than NewReno TCP, that we describe here for the sake of completeness. Consider a scenario with no packet loss, but with sufficient reordering so that the TCP sender receives three duplicate\\n\\nFloyd, et al. Standards Track [Page 13]\\n\\nRFC 3782 NewReno Modification to Fast Recovery Algorithm April 2004\\n\\nacknowledgements. This will trigger the Fast Retransmit and Fast Recovery algorithms. With Reno TCP or with Sack TCP, this will result in the unnecessary retransmission of a single packet, combined with a halving of the congestion window (shown on pages 4 and 6 of [F03]). With NewReno TCP, however, this reordering will also result in the unnecessary retransmission of an entire window of data (shown on page 5 of [F03]).\\n\\nWhile Reno TCP performs better than NewReno TCP in the presence of reordering, NewReno’s superior performance in the presence of multiple packet drops generally outweighs its less optimal performance in the presence of reordering. (Sack TCP is the preferred solution, with good performance in both scenarios.) This document recommends the Fast Retransmit and Fast Recovery algorithms of NewReno TCP instead of those of Reno TCP for those TCP connections that do not support SACK. We would also note that NewReno’s Fast Retransmit and Fast Recovery mechanisms are widely deployed in TCP implementations in the Internet today, as documented in [PF01]. For example, tests of TCP implementations in several thousand web servers in 2001 showed that for those TCP connections where the web browser was not SACK-capable, more web servers used the Fast Retransmit and Fast Recovery algorithms of NewReno than those of Reno or Tahoe TCP [PF01].\\n\\n11. Changes Relative to RFC 2582\\n\\nThe purpose of this document is to advance the NewReno’s Fast Retransmit and Fast Recovery algorithms in RFC 2582 to Standards Track.\\n\\nThe main change in this document relative to RFC 2582 is to specify the Careful variant of NewReno’s Fast Retransmit and Fast Recovery algorithms. The base algorithm described in RFC 2582 did not attempt to avoid unnecessary multiple Fast Retransmits that can occur after a timeout (described in more detail in the section above). However, RFC 2582 also defined \"Careful\" and \"Less Careful\" variants that avoid these unnecessary Fast Retransmits, and recommended the Careful variant. This document specifies the previously-named \"Careful\" variant as the basic version of NewReno. As described below, this algorithm uses a variable \"recover\", whose initial value is the send sequence number.\\n\\nThe algorithm specified in Section 3 checks whether the acknowledgement field of a partial acknowledgement covers *more* than \"recover\", as defined in Section 3. Another possible variant would be to simply require that the acknowledgement field covers *more than or equal to* \"recover\" before initiating another Fast Retransmit. We called this the Less Careful variant in RFC 2582.\\n\\nFloyd, et al. Standards Track [Page 14]\\n\\nRFC 3782 NewReno Modification to Fast Recovery Algorithm April 2004\\n\\nThere are two separate scenarios in which the TCP sender could receive three duplicate acknowledgements acknowledging \"recover\" but no more than \"recover\". One scenario would be that the data sender transmitted four packets with sequence numbers higher than \"recover\", that the first packet was dropped in the network, and the following three packets triggered three duplicate acknowledgements acknowledging \"recover\". The second scenario would be that the sender unnecessarily retransmitted three packets below \"recover\", and that these three packets triggered three duplicate acknowledgements acknowledging \"recover\". In the absence of SACK, the TCP sender is unable to distinguish between these two scenarios.\\n\\nFor the Careful variant of Fast Retransmit, the data sender would have to wait for a retransmit timeout in the first scenario, but would not have an unnecessary Fast Retransmit in the second scenario. For the Less Careful variant to Fast Retransmit, the data sender would Fast Retransmit as desired in the first scenario, and would unnecessarily Fast Retransmit in the second scenario. This document only specifies the Careful variant in Section 3. Unnecessary Fast Retransmits with the Less Careful variant in scenarios with reordering are illustrated in page 8 of [F03].\\n\\nThe document also specifies two heuristics that the TCP sender MAY use to decide to invoke Fast Retransmit even when the three duplicate acknowledgements do not cover more than \"recover\". These heuristics, an ACK-based heuristic and a timestamp heuristic, are described in Sections 6.1 and 6.2 respectively.\\n\\n12. Conclusions\\n\\nThis document specifies the NewReno Fast Retransmit and Fast Recovery algorithms for TCP. This NewReno modification to TCP can even be important for TCP implementations that support the SACK option, because the SACK option can only be used for TCP connections when both TCP end-nodes support the SACK option. NewReno performs better than Reno (RFC 2581) in a number of scenarios discussed herein.\\n\\nA number of options to the basic algorithm presented in Section 3 are also described. These include the handling of the retransmission timer (Section 4), the response to partial acknowledgments (Section 5), and the value of the congestion window when leaving Fast Recovery (section 3, step 5). Our belief is that the differences between these variants of NewReno are small compared to the differences between Reno and NewReno. That is, the important thing is to implement NewReno instead of Reno, for a TCP connection without SACK; it is less important exactly which of the variants of NewReno is implemented.\\n\\nFloyd, et al. Standards Track [Page 15]\\n\\nRFC 3782 NewReno Modification to Fast Recovery Algorithm April 2004\\n\\n13. Security Considerations\\n\\nRFC 2581 discusses general security considerations concerning TCP congestion control. This document describes a specific algorithm that conforms with the congestion control requirements of RFC 2581, and so those considerations apply to this algorithm, too. There are no known additional security concerns for this specific algorithm.\\n\\n14. Acknowledgements\\n\\nMany thanks to Anil Agarwal, Mark Allman, Armando Caro, Jeffrey Hsu, Vern Paxson, Kacheong Poon, Keyur Shah, and Bernie Volz for detailed feedback on this document or on its precursor, RFC 2582.\\n\\n15. References\\n\\n15.1. Normative References\\n\\n[RFC2018] Mathis, M., Mahdavi, J., Floyd, S. and A. Romanow, \"TCP Selective Acknowledgement Options\", RFC 2018, October 1996.\\n\\n[RFC2119] Bradner, S., \"Key words for use in RFCs to Indicate Requirement Levels\", BCP 14, RFC 2119, March 1997.\\n\\n[RFC2581] Allman, M., Paxson, V. and W. Stevens, \"TCP Congestion Control\", RFC 2581, April 1999.\\n\\n[RFC2582] Floyd, S. and T. Henderson, \"The NewReno Modification to TCP’s Fast Recovery Algorithm\", RFC 2582, April 1999.\\n\\n[RFC2988] Paxson, V. and M. Allman, \"Computing TCP’s Retransmission Timer\", RFC 2988, November 2000.\\n\\n[RFC3042] Allman, M., Balakrishnan, H. and S. Floyd, \"Enhancing TCP’s Loss Recovery Using Limited Transmit\", RFC 3042, January 2001.\\n\\n15.2. Informative References\\n\\n[C98] Cardwell, N., \"delayed ACKs for retransmitted packets: ouch!\". November 1998, Email to the tcpimpl mailing list, Message-ID \"Pine.LNX.4.02A.9811021421340.26785- 100000@sake.cs.washington.edu\", archived at \"http://tcp- impl.lerc.nasa.gov/tcp-impl\".\\n\\nFloyd, et al. Standards Track [Page 16]\\n\\nRFC 3782 NewReno Modification to Fast Recovery Algorithm April 2004\\n\\n[F98] Floyd, S., Revisions to RFC 2001, \"Presentation to the TCPIMPL Working Group\", August 1998. URLs \"ftp://ftp.ee.lbl.gov/talks/sf-tcpimpl-aug98.ps\" and \"ftp://ftp.ee.lbl.gov/talks/sf-tcpimpl-aug98.pdf\".\\n\\n[F03] Floyd, S., \"Moving NewReno from Experimental to Proposed Standard? Presentation to the TSVWG Working Group\", March 2003. URLs \"http://www.icir.org/floyd/talks/newreno- Mar03.ps\" and \"http://www.icir.org/floyd/talks/newreno- Mar03.pdf\".\\n\\n[FF96] Fall, K. and S. Floyd, \"Simulation-based Comparisons of Tahoe, Reno and SACK TCP\", Computer Communication Review, July 1996. URL \"ftp://ftp.ee.lbl.gov/papers/sacks.ps.Z\".\\n\\n[F94] Floyd, S., \"TCP and Successive Fast Retransmits\", Technical report, October 1994. URL \"ftp://ftp.ee.lbl.gov/papers/fastretrans.ps\".\\n\\n[GF04] Gurtov, A. and S. Floyd, \"Resolving Acknowledgment Ambiguity in non-SACK TCP\", Next Generation Teletraffic and Wired/Wireless Advanced Networking (NEW2AN’04), February 2004. URL \"http://www.cs.helsinki.fi/u/gurtov/papers/ heuristics.html\".\\n\\n[Gur03] Gurtov, A., \"[Tsvwg] resolving the problem of unnecessary fast retransmits in go-back-N\", email to the tsvwg mailing list, message ID <3F25B467.9020609@cs.helsinki.fi>, July 28, 2003. URL \"http://www1.ietf.org/mail-archive/working- groups/tsvwg/current/msg04334.html\".\\n\\n[Hen98] Henderson, T., Re: NewReno and the 2001 Revision. September 1998. Email to the tcpimpl mailing list, Message ID \"Pine.BSI.3.95.980923224136.26134A- 100000@raptor.CS.Berkeley.EDU\", archived at \"http://tcp- impl.lerc.nasa.gov/tcp-impl\".\\n\\n[Hoe95] Hoe, J., \"Startup Dynamics of TCP’s Congestion Control and Avoidance Schemes\", Master’s Thesis, MIT, 1995.\\n\\n[Hoe96] Hoe, J., \"Improving the Start-up Behavior of a Congestion Control Scheme for TCP\", ACM SIGCOMM, August 1996. URL \"http://www.acm.org/sigcomm/sigcomm96/program.html\".\\n\\n[LM97] Lin, D. and R. Morris, \"Dynamics of Random Early Detection\", SIGCOMM 97, September 1997. URL \"http://www.acm.org/sigcomm/sigcomm97/program.html\".\\n\\nFloyd, et al. Standards Track [Page 17]\\n\\nRFC 3782 NewReno Modification to Fast Recovery Algorithm April 2004\\n\\n[NS] The Network Simulator (NS). URL \"http://www.isi.edu/nsnam/ns/\".\\n\\n[PF01] Padhye, J. and S. Floyd, \"Identifying the TCP Behavior of Web Servers\", June 2001, SIGCOMM 2001.\\n\\n[RFC1323] Jacobson, V., Braden, R. and D. Borman, \"TCP Extensions for High Performance\", RFC 1323, May 1992.\\n\\n[RFC3517] Blanton, E., Allman, M., Fall, K. and L. Wang, \"A Conservative Selective Acknowledgment (SACK)-based Loss Recovery Algorithm for TCP\", RFC 3517, April 2003.\\n\\n[RFC3522] Ludwig, R. and M. Meyer, \"The Eifel Detection Algorithm for TCP\", RFC 3522, April 2003.\\n\\nAuthors’ Addresses\\n\\nSally Floyd International Computer Science Institute\\n\\nPhone: +1 (510) 666-2989 EMail: floyd@acm.org URL: http://www.icir.org/floyd/\\n\\nTom Henderson The Boeing Company\\n\\nEMail: thomas.r.henderson@boeing.com\\n\\nAndrei Gurtov TeliaSonera\\n\\nEMail: andrei.gurtov@teliasonera.com\\n\\nFloyd, et al. Standards Track [Page 18]\\n\\nRFC 3782 NewReno Modification to Fast Recovery Algorithm April 2004\\n\\nFull Copyright Statement\\n\\nCopyright (C) The Internet Society (2004). This document is subject to the rights, licenses and restrictions contained in BCP 78, and except as set forth therein, the authors retain all their rights.\\n\\nThis document and the information contained herein are provided on an \"AS IS\" basis and THE CONTRIBUTOR, THE ORGANIZATION HE/SHE REPRESENTS OR IS SPONSORED BY (IF ANY), THE INTERNET SOCIETY AND THE INTERNET ENGINEERING TASK FORCE DISCLAIM ALL WARRANTIES, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO ANY WARRANTY THAT THE USE OF THE INFORMATION HEREIN WILL NOT INFRINGE ANY RIGHTS OR ANY IMPLIED WARRANTIES OF MERCHANTABILITY OR FITNESS FOR A PARTICULAR PURPOSE.\\n\\nIntellectual Property\\n\\nThe IETF takes no position regarding the validity or scope of any Intellectual Property Rights or other rights that might be claimed to pertain to the implementation or use of the technology described in this document or the extent to which any license under such rights might or might not be available; nor does it represent that it has made any independent effort to identify any such rights. Information on the procedures with respect to rights in RFC documents can be found in BCP 78 and BCP 79.\\n\\nCopies of IPR disclosures made to the IETF Secretariat and any assurances of licenses to be made available, or the result of an attempt made to obtain a general license or permission for the use of such proprietary rights by implementers or users of this specification can be obtained from the IETF on-line IPR repository at http://www.ietf.org/ipr.\\n\\nThe IETF invites any interested party to bring to its attention any copyrights, patents or patent applications, or other proprietary rights that may cover technology that may be required to implement this standard. Please address the information to the IETF at ietf-ipr@ietf.org.\\n\\nAcknowledgement\\n\\nFunding for the RFC Editor function is currently provided by the Internet Society.\\n\\nFloyd, et al. Standards Track [Page 19]')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f515a23-e265-4cc2-8502-ff4fe0c75699",
   "metadata": {},
   "source": [
    "Each document object contains metadata, such as the document title, as well as the raw text."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fab1399e-9c12-4ab4-9554-b86b4aac2d00",
   "metadata": {},
   "source": [
    "### Creating a Vector Store"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72d5cf8f-f132-459b-aed9-fc4825c8fd42",
   "metadata": {},
   "source": [
    "Now that we have extracted the text from the PDFs, we must further process our data so that it can be efficiently searched by our pipeline. We will do this by saving our documents into a **vector store**.\n",
    "\n",
    "#### Chunking\n",
    "\n",
    "The vectors will be created using an embedding model, but before we do this, we must **chunk** our documents. We have to do this because embedding models have a context limit, and some of our documents are too large to fit into a single vector. For example, the embedding model that we're using, `mxbai-embed-large`, has a context limit of 512 tokens (per its [datasheet](https://ollama.com/library/mxbai-embed-large)).\n",
    "\n",
    "How you chunk your documents is important, because each chunk should represent a coherent idea that reflects the intended meaning from the original document. If your chunks are too large, you risk feeding your pipeline unnecessary or only tangentially relevant information. If your chunks are too small, then you may lose essential context that helps the retriever and model understand what a chunk is actually about. Consider this example:\n",
    "\n",
    "> Red squirrels have a varied and adaptable diet that changes with the seasons. They primarily eat seeds from conifer cones, such as pine, spruce, and fir, carefully stripping the cones to reach the nutritious seeds inside. In addition to seeds, they consume nuts, berries, fruits, buds, and fungi, especially mushrooms. Red squirrels are also known to occasionally eat insects, bird eggs, or nestlings when plant food is scarce.\n",
    "\n",
    "> Red squirrels typically live in forests dominated by coniferous or mixed trees, which provide both food and shelter. They build nests, called dreys, high in the trees using twigs, leaves, moss, and bark for insulation. Some individuals also use hollow trees or abandoned woodpecker holes for nesting. Their habitat usually includes well-defined territories that they actively defend from other squirrels.\n",
    "\n",
    "If we combine both paragraphs into a single chunk, then a query about the diet of red squirrels will retrieve information about their habitat and nesting behavior as well. While this information is related, it is not directly relevant to the question being asked. As a result, the retrieved context may fill up the model’s context window more quickly and crowd out other, more relevant chunks from different documents.\n",
    "\n",
    "On the other hand, if we split the document too aggressively (e.g., by making each sentence into its own chunk), then the sentences' original context is lost. Important information that is implicit in the surrounding sentences may no longer be available to the retriever. For example, if a user asks, \"What do red squirrels eat?\", the retriever may fail to identify the following sentence as relevant:\n",
    "\n",
    "> They primarily eat seeds from conifer cones, such as pine, spruce, and fir, carefully stripping the cones to reach the nutritious seeds inside.\n",
    "\n",
    "On its own, this sentence does not explicitly mention red squirrels. Without the surrounding context, the retriever (and the model) has no clear signal that the sentence is describing the diet of red squirrels rather than some other animal.\n",
    "\n",
    "In this example, the best method would be to treat each paragraph as its own chunk, as each paragraph has a distinct topic.\n",
    "\n",
    "Of course, we cannot manually chunk every document. Instead, chunking tools allow us to specify chunk sizes, and also include chunk overlaps, which help avoid context loss. Here, I've specified 1200 characters, which is about the length of a short paragraph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e005b51b-f1c3-4494-a058-f84c79f49502",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 6 docs -> split into 39\n"
     ]
    }
   ],
   "source": [
    "chunk_size = 10000\n",
    "chunk_overlap = int(.2 * chunk_size)\n",
    "# separators=[\"\\n\\n\", \"\\n\", \". \", \" \", \"\"]\n",
    "separators=[\"\\n\\n\", \"\\n\"]\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=chunk_size, # 1200 characters. mxbai-embed-large is limited to 512 tokens (~1500-1600 characters)\n",
    "    chunk_overlap=chunk_overlap,\n",
    "    length_function=len,\n",
    "    separators=separators,\n",
    ")\n",
    "split_docs = text_splitter.split_documents(documents)\n",
    "print(f\"Loaded {len(documents)} docs -> split into {len(split_docs)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5813b4f8-bdfc-47d5-891d-a7631247dda5",
   "metadata": {},
   "source": [
    "After splitting, we have multiple documents, each representing a different chunk of each source:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ffc6f005",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NewReno.pdf\n",
      "NewReno.pdf\n",
      "NewReno.pdf\n",
      "NewReno.pdf\n",
      "NewReno.pdf\n",
      "NewReno.pdf\n",
      "CUBIC.pdf\n",
      "CUBIC.pdf\n",
      "CUBIC.pdf\n",
      "CUBIC.pdf\n",
      "CUBIC.pdf\n",
      "CUBIC.pdf\n",
      "CUBIC.pdf\n",
      "Hybla.pdf\n",
      "Hybla.pdf\n",
      "Hybla.pdf\n",
      "Hybla.pdf\n",
      "Hybla.pdf\n",
      "Hybla.pdf\n",
      "Hybla.pdf\n",
      "Hybla.pdf\n",
      "comparative_study.pdf\n",
      "comparative_study.pdf\n",
      "comparative_study.pdf\n",
      "comparative_study.pdf\n",
      "comparative_study.pdf\n",
      "CUBIC-checkpoint.pdf\n",
      "CUBIC-checkpoint.pdf\n",
      "CUBIC-checkpoint.pdf\n",
      "CUBIC-checkpoint.pdf\n",
      "CUBIC-checkpoint.pdf\n",
      "CUBIC-checkpoint.pdf\n",
      "CUBIC-checkpoint.pdf\n",
      "BBR.pdf\n",
      "BBR.pdf\n",
      "BBR.pdf\n",
      "BBR.pdf\n",
      "BBR.pdf\n",
      "BBR.pdf\n"
     ]
    }
   ],
   "source": [
    "for doc in split_docs:\n",
    "    print(doc.metadata[\"source\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b031e72",
   "metadata": {},
   "source": [
    "#### Converting Chunks into Vectors\n",
    "\n",
    "The final step of data preparation is to convert our documents into \"vectors,\" which are numerical representations that capture the meaning of words, sentences, and passages. This allows the pipeline to efficiently run a similarity search with queries to extract contextually relevant documents.\n",
    "\n",
    "*How do we choose an embedding model?*\n",
    "\n",
    "The embedded documents get saved to a Chroma database (\"vector store\"):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "605a7a38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langchain_chroma.vectorstores.Chroma at 0x14f99ad1f7a0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Chroma.from_documents(documents=split_docs,\n",
    "                      embedding=embeddings,\n",
    "                      persist_directory=VECTOR_STORE_PATH) # Specifying persist_directory saves the vector store as a file so we don't have to recreate it"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bae4005",
   "metadata": {},
   "source": [
    "Once the vector store has been saved to a file, you can read it using the following command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "aa0f3f22",
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_store = Chroma(persist_directory=VECTOR_STORE_PATH,\n",
    "                      embedding_function=embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6910fc6a-4753-4cbd-a4b2-adbbf51b9bfb",
   "metadata": {},
   "source": [
    "Now that we have a vector store, we can evaluate its ability to retrieve relevant information using similarity searches. For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "87f7397f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BBR.pdf (0.75)\n",
      "BBR.pdf (0.75)\n",
      "BBR.pdf (0.8)\n",
      "BBR.pdf (0.8)\n",
      "BBR.pdf (0.83)\n"
     ]
    }
   ],
   "source": [
    "def get_relevant_docs(query, vector_store):\n",
    "    results = vector_store.similarity_search_with_score(\n",
    "        query, k=5\n",
    "    )\n",
    "    for res, score in results:\n",
    "        # print(f\"* [SIM={score:3f}] {res.page_content} [{res.metadata}]\")\n",
    "        print(res.metadata[\"source\"], f\"({round(score, 2)})\")\n",
    "\n",
    "query = \"How is BBR related to bottlenecks?\"\n",
    "get_relevant_docs(query, vector_store)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ce66aed-09ce-4450-80d4-47c45688127e",
   "metadata": {},
   "source": [
    "~~Our retriever seems to be working well, as it knows it can find helpful information about VS Code in the \"VSCode Remote SSH\" document. Let's try something a bit more complicated:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8ec85ce-5945-4060-85c0-8fb260280fff",
   "metadata": {},
   "source": [
    "## Running RAG"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db3f1d81",
   "metadata": {},
   "source": [
    "Play around with LLM:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "20c5526d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "The Massachusetts Institute of Technology (MIT) is located in Cambridge, Massachusetts, United States. Specifically:\n",
       "\n",
       "* Address: 77 Massachusetts Avenue, Cambridge, MA 02139\n",
       "* Located about 0.5 miles from downtown Boston and the Charles River.\n",
       "\n",
       "MIT's campus spans across several buildings and facilities in the Kendall Square area of Cambridge, with some satellite locations nearby."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "llm = OllamaLLM(model=LLM_NAME, temperature=0.5)\n",
    "display(Markdown(llm.invoke(\"Where is MIT located?\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be523553",
   "metadata": {},
   "source": [
    "Set up the RAG pipeline:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c37b4783",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "@dynamic_prompt\n",
    "def prompt_with_context(request: ModelRequest) -> str:\n",
    "    \"\"\"Inject context into state messages.\"\"\"\n",
    "    last_query = request.state[\"messages\"][-1].text\n",
    "    retrieved_docs = vector_store.similarity_search(last_query, k=3)\n",
    "\n",
    "    docs_content = \"\\n\\n\".join(doc.page_content for doc in retrieved_docs)\n",
    "    # print(docs_content) ##\n",
    "\n",
    "    # Print documents used:\n",
    "    print(\"\\nRetrieved documents:\") ##\n",
    "    for doc in retrieved_docs: ##\n",
    "        print(doc.metadata[\"source\"]) ##\n",
    "    print()\n",
    "\n",
    "    system_message = (\n",
    "        \"You are a helpful assistant. Answer only using the information from the following documents.\"\n",
    "        f\"\\n\\n{docs_content}\"\n",
    "    )\n",
    "\n",
    "    return system_message\n",
    "\n",
    "\n",
    "agent = create_agent(llm, tools=[], middleware=[prompt_with_context])\n",
    "\n",
    "def pose(query):\n",
    "    for step in agent.stream(\n",
    "        {\"messages\": [{\"role\": \"user\", \"content\": query}]},\n",
    "        stream_mode=\"values\",\n",
    "    ):\n",
    "        display(Markdown(step[\"messages\"][-1].text))\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf177d3f-75bc-4b28-b247-a8dc5cd4bb6c",
   "metadata": {},
   "source": [
    "Example questions I got from NotebookLM:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "12fd7b93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "How do the design philosophies of BBR, CUBIC, and NewReno differ in their interpretation of network 'signals'?"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Retrieved documents:\n",
      "BBR.pdf\n",
      "BBR.pdf\n",
      "BBR.pdf\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "The design philosophies of BBR (Bottleneck Bandwidth and Round-trip time), CUBIC, and NewReno differ in their interpretation of network \"signals\" as follows:\n",
       "\n",
       "1.  **NewReno**: NewReno uses packet loss as a primary signal to indicate congestion. It assumes that packet loss is caused by the network being congested, and it reacts to this loss by reducing its transmission rate.\n",
       "\n",
       "2.  **CUBIC**: CUBIC also relies heavily on packet loss but introduces some improvements over NewReno. It tries to estimate the bottleneck bandwidth (BtlBw) more accurately using a combination of algorithms that measure the network's capacity and the round-trip time (RTT). However, it still primarily uses packet loss as an indicator of congestion.\n",
       "\n",
       "3.  **BBR**: BBR takes a fundamentally different approach by not relying on packet loss to signal congestion. Instead, it focuses on measuring the available bandwidth and RTT directly through probing mechanisms like ProbeRTT and ProbeBW. These probes allow BBR to estimate the bottleneck bandwidth more accurately and react accordingly without waiting for packet loss.\n",
       "\n",
       "In summary, while NewReno and CUBIC both use packet loss as a primary signal for congestion, BBR focuses on measuring network capacity and RTT directly through probing mechanisms, making it less dependent on packet loss as an indicator of congestion."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "query = \"How do the design philosophies of BBR, CUBIC, and NewReno differ in their interpretation of network 'signals'?\"\n",
    "pose(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3d59d090-19b6-4be7-a8c5-15f20ff4d9b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Why does TCP Vegas perform poorly in LEO satellite networks compared to BBR?"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Retrieved documents:\n",
      "comparative_study.pdf\n",
      "comparative_study.pdf\n",
      "comparative_study.pdf\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "TCP Vegas performs poorly in LEO satellite networks compared to BBR because of its sensitivity to network delay. In a LEO satellite network, the satellites and ground devices are constantly moving, causing path changes and latency variations. TCP Vegas detects congestion by measuring increases in round-trip time (RTT), which can be caused by these path changes rather than actual congestion. As a result, it may react too quickly to perceived congestion, reducing its sending rate and leading to low throughput.\n",
       "\n",
       "In contrast, BBR is more resilient to network delay variations because it frequently measures the bottleneck bandwidth and minimal RTT to obtain the bandwidth-delay product (BDP) of the path. This allows it to regulate its sending rate in a way that takes into account the dynamic nature of the LEO satellite network, resulting in better performance.\n",
       "\n",
       "Additionally, the nearest-satellite strategy used in the simulations can also contribute to TCP Vegas's poor performance. When using this strategy, the ground device may connect to a satellite that is not on the shortest path to the destination, leading to higher latency and more frequent path changes, which can trigger TCP Vegas's congestion detection mechanism unnecessarily.\n",
       "\n",
       "Overall, the combination of TCP Vegas's sensitivity to network delay and the nearest-satellite strategy used in the simulations contribute to its poor performance in LEO satellite networks compared to BBR."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "query = \"Why does TCP Vegas perform poorly in LEO satellite networks compared to BBR?\"\n",
    "pose(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2b886af2-6136-48cc-bc95-387a3d178d5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Compare how TCP CUBIC and TCP Hybla address the problem of 'RTT Unfairness.'"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Retrieved documents:\n",
      "CUBIC.pdf\n",
      "CUBIC-checkpoint.pdf\n",
      "CUBIC-checkpoint.pdf\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "TCP CUBIC and TCP Hybla are both high-speed TCP variants designed to improve network utilization and fairness in environments with varying Round-Trip Times (RTTs). While they share some similarities, they approach the problem of RTT unfairness differently.\n",
       "\n",
       "**TCP CUBIC:**\n",
       "\n",
       "TCP CUBIC addresses RTT unfairness by employing a cubic growth function for congestion avoidance. This means that the sender's window size grows cubically with time, rather than linearly or exponentially as in traditional TCP. The cubic growth function helps to reduce the impact of RTT variations on fairness and ensures that senders with longer RTTs do not starve senders with shorter RTTs.\n",
       "\n",
       "**TCP Hybla:**\n",
       "\n",
       "TCP Hybla, on the other hand, uses a modified additive increase/multiplicative decrease (AIMD) algorithm to address RTT unfairness. The key innovation in TCP Hybla is its use of a dynamic increase phase, where the sender's window size increases multiplicatively with time, and a multiplicative decrease phase, where the window size decreases multiplicatively when congestion is detected. This approach helps to reduce the impact of RTT variations on fairness by allowing senders with longer RTTs to catch up with senders having shorter RTTs.\n",
       "\n",
       "**Comparison:**\n",
       "\n",
       "While both TCP CUBIC and TCP Hybla address RTT unfairness, they differ in their approaches:\n",
       "\n",
       "*   TCP CUBIC uses a cubic growth function for congestion avoidance, which helps to reduce the impact of RTT variations on fairness.\n",
       "*   TCP Hybla employs a modified AIMD algorithm with dynamic increase and multiplicative decrease phases, allowing senders with longer RTTs to catch up with those having shorter RTTs.\n",
       "\n",
       "In summary, both TCP CUBIC and TCP Hybla are designed to improve network utilization and fairness in environments with varying RTTs. However, they approach the problem of RTT unfairness differently, with TCP CUBIC using a cubic growth function and TCP Hybla employing a modified AIMD algorithm."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "query = \"Compare how TCP CUBIC and TCP Hybla address the problem of 'RTT Unfairness.'\"\n",
    "pose(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8b47f5c2-a5f8-4e7a-a8a8-9ba7d709277f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "What is the significance of the 'recover' variable and 'Partial ACKs' in the NewReno algorithm?"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Retrieved documents:\n",
      "NewReno.pdf\n",
      "NewReno.pdf\n",
      "NewReno.pdf\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "The `recover` variable is a state variable that keeps track of the highest sequence number acknowledged by the receiver. It plays a crucial role in the NewReno algorithm.\n",
       "\n",
       "When the sender receives duplicate acknowledgments (ACKs) indicating that a segment has been lost, it enters the Fast Recovery procedure. In this procedure, the sender uses the `recover` variable to determine whether the duplicate ACKs are due to a lost segment or unnecessary retransmissions.\n",
       "\n",
       "If the cumulative acknowledgment field in the latest non-duplicate ACK does not cover more than the value stored in the `recover` variable, it indicates that the duplicate ACKs are likely due to unnecessary retransmissions. In this case, the sender proceeds with Step 1B of the NewReno algorithm, which involves halving the congestion window and continuing to send segments.\n",
       "\n",
       "However, if the cumulative acknowledgment field does cover more than the value stored in the `recover` variable, it indicates that a segment has been lost. In this case, the sender proceeds with Step 1A of the NewReno algorithm, which involves sending a new segment and adjusting the congestion window accordingly.\n",
       "\n",
       "The `recover` variable is essential for distinguishing between duplicate ACKs caused by a lost segment and those caused by unnecessary retransmissions. Its value helps the sender to correctly implement the Fast Recovery procedure and avoid unnecessary retransmissions.\n",
       "\n",
       "Regarding \"Partial ACKs\", in the context of NewReno, a Partial ACK is an acknowledgment that indicates some segments have been received out of order or missing. When the receiver sends a partial ACK, it includes the sequence number of the first segment that was not received correctly. The sender uses this information to determine which segments are missing and needs to be retransmitted.\n",
       "\n",
       "In NewReno, Partial ACKs play a crucial role in accelerating loss recovery by allowing the sender to quickly identify and retransmit missing segments. When the sender receives a partial ACK, it can immediately send new segments, reducing the time spent in the Fast Recovery procedure.\n",
       "\n",
       "The use of partial ACKs in NewReno is based on the idea that the receiver should acknowledge out-of-order data segments immediately, as specified in RFC 2581. This allows the sender to respond quickly to packet losses and reduce the time spent in the recovery process."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "query = \"What is the significance of the 'recover' variable and 'Partial ACKs' in the NewReno algorithm?\"\n",
    "pose(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4094c912-ade1-46e4-b38c-9ca344f2f80a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Explain the sequential relationship between BBR’s 'Startup' and 'Drain' states."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Retrieved documents:\n",
      "BBR.pdf\n",
      "BBR.pdf\n",
      "BBR.pdf\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "BBR's 'Startup' and 'Drain' states are sequentially related in the following way:\n",
       "\n",
       "1. When a new connection is established, the BBR flow enters the 'Startup' state.\n",
       "2. In this state, the flow grows its inflight (the amount of data being transmitted) aggressively to quickly fill the available bandwidth.\n",
       "3. As the inflight increases, the round-trip time (RTT) also increases due to the growing queue at the bottleneck link.\n",
       "4. When the RTT reaches a certain threshold (clamped by cwnd_gain), the flow transitions from 'Startup' to 'Drain'.\n",
       "5. In the 'Drain' state, the flow uses an inverse gain to reduce its inflight and get rid of any excess packets in the queue.\n",
       "6. Once the inflight drops to a BDP (Bandwidth-Delay Product), the flow returns to the 'ProbeBW' state.\n",
       "\n",
       "In summary, the 'Startup' state is used for rapidly filling the available bandwidth, while the 'Drain' state is used for reducing the inflight and getting rid of excess packets in the queue. The transition from 'Startup' to 'Drain' occurs when the RTT reaches a certain threshold, indicating that the flow has reached its maximum allowed inflight."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "query = \"Explain the sequential relationship between BBR’s 'Startup' and 'Drain' states.\"\n",
    "pose(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9aef283-2819-4d0d-a60e-0ad750266568",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag_ollama",
   "language": "python",
   "name": "rag_ollama"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
