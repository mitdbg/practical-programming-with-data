{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7d4cd27d",
   "metadata": {},
   "source": [
    "**TODO:**\n",
    "- Look into further ways we can play with metadata\n",
    "- Add structured data portion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7e3923b-98e3-421f-a9a1-d6ed09264e13",
   "metadata": {},
   "source": [
    "# Retrieval Augmented Generation with Unstructured Data using GPUs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f31fb1f8",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "Using the command line, create a new Conda environment using the `environment.yml` file:\n",
    "```bash\n",
    "module load miniforge\n",
    "conda env create -f environment.yml\n",
    "conda activate rag_ollama\n",
    "```\n",
    "\n",
    "Alternatively, install the necessary packages manually:\n",
    "\n",
    "```bash\n",
    "module load miniforge\n",
    "conda create -n rag_ollama jupyterlab langchain-ollama langchain-chroma langchain-community\n",
    "conda activate rag_ollama\n",
    "pip install \"unstructured[pdf]\"\n",
    "```\n",
    "\n",
    "Create a Jupyter kernel for your environment:\n",
    "```bash\n",
    "python -m ipykernel install --user --name rag_ollama\n",
    "```\n",
    "\n",
    "Connect this notebook to the Jupyter kernel you just created. You may need to disconnect from and reconnect to your Jupyter session.\n",
    "\n",
    "Run the setup script to start Ollama and download the embedding and language models:\n",
    "```bash\n",
    "sh start_ollama.sh\n",
    "```\n",
    "\n",
    "Import packages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "337f9305",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/secorey/orcd/scratch/.conda/envs/rag_ollama/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_ollama import OllamaEmbeddings, OllamaLLM\n",
    "from langchain_community.document_loaders import UnstructuredPDFLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain.agents.middleware import dynamic_prompt, ModelRequest\n",
    "from langchain.agents import create_agent\n",
    "import logging\n",
    "from IPython.display import Markdown, display"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3425058e",
   "metadata": {},
   "source": [
    "Set environment variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7156e55c",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"config.json\", \"r\") as f:\n",
    "    config = json.load(f)\n",
    "\n",
    "EMBEDDING_MODEL_NAME = config[\"embedding_model\"]\n",
    "LLM_NAME = config[\"llm\"]\n",
    "\n",
    "DOCS_PATH = os.path.join(os.getcwd(), \"docs\")\n",
    "VECTOR_STORE_PATH = os.path.join(os.getcwd(), \"vector_store\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87272f73",
   "metadata": {},
   "source": [
    "Initialize components:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7a55fbf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = OllamaEmbeddings(\n",
    "    model=EMBEDDING_MODEL_NAME\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57bef930",
   "metadata": {},
   "source": [
    "## Processing PDFs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "459b8f3f-1847-4bd8-87a9-098913b93e72",
   "metadata": {},
   "source": [
    "We have a set of PDFs that we would like to input into our RAG pipeline. We cannot do this directly, however. While PDFs are optimized for humans to read and comprehend, machines have a harder time. So, we must first process our documents so that they can be efficiently searched by a computer. We will do this in two steps:\n",
    "1. Extract the raw text from the PDFs\n",
    "2. Convert the text into vectors using an embedding model\n",
    "\n",
    "### Extracting Text from PDFs\n",
    "\n",
    "The `unstructured` software has a PDF loading tool that extracts text from PDFs and ignores images. This software uses the `pdfminer.six` Python package under the hood, which is very popular for reading PDFs using Python.\n",
    "\n",
    "*Note: `unstructured` has loaders for other file formats as well, such as Markdown or Word documents.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9fbbddc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mute pdfminer warnings globally\n",
    "logging.getLogger(\"pdfminer\").setLevel(logging.ERROR)\n",
    "logging.getLogger(\"pdfminer.pdffont\").setLevel(logging.ERROR)\n",
    "\n",
    "def load_documents(docs_path):\n",
    "    \"\"\"\n",
    "    Load documents from the specified directory recursively. Documents must be\n",
    "    in .pdf format.\n",
    "    \"\"\"\n",
    "\n",
    "    # Load the documents recursively:\n",
    "    documents = []\n",
    "    for file_name in os.listdir(docs_path):\n",
    "        file_path = os.path.join(docs_path, file_name)\n",
    "        if file_name.endswith('.pdf'):\n",
    "            loader = UnstructuredPDFLoader(file_path, languages=[\"eng\"])\n",
    "            doc = loader.load()\n",
    "            doc[0].metadata[\"source\"] = file_name\n",
    "            documents.extend(doc)\n",
    "        elif os.path.isdir(file_path):\n",
    "            documents.extend(load_documents(file_path))\n",
    "    return documents\n",
    "\n",
    "documents = load_documents(DOCS_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cd5496c",
   "metadata": {},
   "source": [
    "This creates a list of documents:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "56dfe2b5-dffb-4989-9887-34db59320da2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(metadata={'source': 'CUBIC-checkpoint.pdf'}, page_content='CUBIC: A New TCP-Friendly High-Speed TCP Variant ∗\\n\\nSangtae Ha, Injong Rhee Dept of Computer Science North Carolina State University Raleigh, NC 27695 {sha2,rhee}@ncsu.edu\\n\\nLisong Xu Dept of Comp. Sci. and Eng. University of Nebraska Lincoln, Nebraska 68588 xu@cse.unl.edu\\n\\nABSTRACT CUBIC is a congestion control protocol for TCP (transmis- sion control protocol) and the current default TCP algo- rithm in Linux. The protocol modiﬁes the linear window growth function of existing TCP standards to be a cubic function in order to improve the scalability of TCP over fast and long distance networks. It also achieves more eq- uitable bandwidth allocations among ﬂows with diﬀerent RTTs (round trip times) by making the window growth to be independent of RTT – thus those ﬂows grow their conges- tion window at the same rate. During steady state, CUBIC increases the window size aggressively when the window is far from the saturation point, and the slowly when it is close to the saturation point. This feature allows CUBIC to be very scalable when the bandwidth and delay product of the network is large, and at the same time, be highly stable and also fair to standard TCP ﬂows. The implementation of CUBIC in Linux has gone through several upgrades. This paper documents its design, implementation, performance and evolution as the default TCP algorithm of Linux.\\n\\n1. As the Internet evolves to include many very high speed and long distance network paths, the performance of TCP was challenged. These networks are characterized by large bandwidth and delay product (BDP) which represents the total number of packets needed in ﬂight while keeping the bandwidth fully utilized, in other words, the size of the con- gestion window. In standard TCP like TCP-Reno, TCP- NewReno and TCP-SACK, TCP grows its window one per round trip time (RTT). This makes the data transport speed of TCP∗ used in all major operating systems including Win- dows and Linux rather sluggish, to say the least, extremely under-utilizing the networks especially if the length of ﬂows is much shorter than the time TCP grows its windows to the full size of the BDP of a path. For instance, if the band- width of a network path is 10 Gbps and the RTT is 100 ms, with packets of 1250 bytes, the BDP of the path is around 100,000 packets. For TCP to grow its window from the mid- point of the BDP, say 50,000, it takes about 50,000 RTTs which amounts to 5000 seconds (1.4 hours). If a ﬂow ﬁnishes before that time, it severely under-utilizes the path. To counter this under-utilization problem of TCP, many\\n\\nINTRODUCTION\\n\\n∗A short version [27] of this paper was presented at the Inter- national Workshop on Protocols for Fast and Long Distance Networks in 2005. ∗For brevity, we also denote Standard TCP as TCP.\\n\\n“high-speed” TCP variants are proposed (e.g., FAST [24], HSTCP [15], STCP [25], HTCP [28], SQRT [19], West- wood [14], and BIC-TCP [30]). Recognizing this problem with TCP, the Linux community responded quickly to im- plement a majority of these protocols in Linux and ship them as part of its operating system. After a series of third- party testing and performance validation [11, 21], in 2004, from version 2.6.8, it selected BIC-TCP as the default TCP algorithm and the other TCP variants as optional.\\n\\nWhat makes BIC-TCP stand out from other TCP algor- tihms is its stability. It uses a binary search algorithm where the window grows to the mid-point between the last win- dow size (i.e., max) where TCP has a packet loss and the last window size (i.e., min) it does not have a loss for one RTT period. This “search” into the mid-point intuitively makes sense because the capacity of the current path must be somewhere between the two min and max window sizes if the network conditions do not quickly change since the last congestion signal (which is the last packet loss). After the window grows to the mid-point, if the network does not have packet losses, then it means that the network can han- dle more traﬃc and thus BIC-TCP sets the mid-point to be the new min and performs another “binary-search” with the min and max windows. This has an eﬀect of growing the window really fast when the current window size is far from the available capacity of the path, and furthermore, if it is close to the available capacity (where we had the pre- vious loss), it slowly reduces its window increment. It has the smallest window increment at the saturation point and its overshoots amount beyond the saturation point where losses occur very small. The whole window growth func- tion is simply a logarithmic concave function. This concave function keeps the congestion window much longer at the saturation point or equilibrium than convex or linear func- tions where they have the largest window increment at the saturation point and thus have the largest overshoot at the time packet losses occur. These features make BIC-TCP very stable and at the same time highly scalable.\\n\\nBIC-TCP trades the speed to react to changes in avail- able bandwidth (i.e., convergence speed) for stability. If the available capacity has increased since the last packet losses, the window can grow beyond the max without having a loss. At that time, BIC-TCP increases the window exponentially. Note that an exponential function (a convex function) grows very slowly at the beginning (slower than a linear function). This feature adds to the stability of the protocol because\\n\\neven if the protocol makes mistakes in ﬁnding the max win- dow, it ﬁnds the next max window near the previous max point ﬁrst, thus staying at the previous saturation point longer. But the exponential function quickly catches up and its increment becomes very large if the losses do not occur (in which case, the saturation point has become much larger than the previous one). Because it stays longer near the pre- vious saturation point than other variants, it can be slug- gish to ﬁnd the new saturation point if the saturation point has increased far beyond the last one. BIC-TCP, however, safely reacts fast to reduced capacity because packet losses occur before the previous max and it reduces the window by a multiplicative factor. This tradeoﬀ is a design choice of BIC-TCP. It is known [31] that available bandwidth in the Internet change over a long time scale of several hours. Given that packet losses would occur very asynchronously and also proportionally to the bandwidth consumption of a ﬂow under a highly statistically multiplexed environment, fast convergence is a natural consequence of the network en- vironment – something the protocol does not have to force. Thus, although BIC-TCP may converge slowly under low statistical multiplexing where only a few ﬂows are compet- ing, its convergence speed is not an issue under typical In- ternet environments.\\n\\nCUBIC [27] is the next version of BIC-TCP. It greatly sim- pliﬁes the window adjustment algorithm of BIC-TCP by re- placing the concave and convex window growth portions of BIC-TCP by a cubic function (which contains both concave and convex portions). In fact, any odd order polynomial function has this shape. The choice for a cubic function is incidental and out of convenience. The key feature of CU- BIC is that its window growth depends only on the real time between two consecutive congestion events. One congestion event is the time when TCP undergoes fast recovery. We call this real time a congestion epoch. Thus, the window growth becomes independent of RTTs. This feature allows CUBIC ﬂows competing in the same bottleneck to have approxi- mately the same window size independent of their RTTs, achieving good RTT-fairness. Furthermore, when RTTs are short, since the window growth rate is ﬁxed, its growth rate could be slower than TCP standards. Since TCP standards (e.g., TCP-SACK) work well under short RTTs, this feature enhances the TCP-friendliness of the protocol.\\n\\nThe implementation of CUBIC in Linux has gone through several upgrades. The most notable upgrade is the eﬃcient implementation of cubic root calculation. Since it requires a ﬂoating point operation, implementing it in the kernel re- quires some integer approximation. Initially it used the bi- section method and later changed to the Newton-Raphson method which reduces the computational cost almost by 10 times. Another change to CUBIC after inception is the re- moval of window clamping. Window clamping was intro- duced in BIC-TCP where window increments are clamped to a maximum increment and was inherited to CUBIC for the ﬁrst version. This forces the window growth to be linear when the target mid-point is much larger than the current window size. The authors conclude that this feature is not needed after extensive testing due to the increased stability of CUBIC. CUBIC replaced BIC-TCP as the default TCP algorithm in 2006 after version 2.6.18. The changes and upgrades of CUBIC in Linux are documented in Table 1.\\n\\nThe remainder of this paper is organized as follows. Section 2 gives related work, Section 3 presents the details of CU- BIC algorithms in Linux, Section 4 includes the evolution of CUBIC and its implementation in Linux, and Section 5 includes discussion related to fairness property of CUBIC. Section 6 presents the results of experimental evaluation and Section 7 gives conclusion.\\n\\n2. RELATED WORK Kelly proposed Scalable TCP (STCP) [25]. The design ob- jective of STCP is to make the recovery time from loss events be constant regardless of the window size. This is why it is called “Scalable”. Note that the recovery time of TCP- NewReno largely depends on the current window size. HighSpeed TCP (HSTCP) [15] uses a generalized AIMD where the linear increase factor and multiplicative decrease factor are adjusted by a convex fucntion of the current con- gestion window size. When the congestion window is less than some cutoﬀ value, HSTCP uses the same factors as TCP. Most of high-speed TCP variants support this form of TCP compatibility, which is based on the window size. When the window grows beyond the cutoﬀ point, the con- vex function increases the increase factor and reduces the decrease factor proportionally to the window size.\\n\\nHTCP [28], like CUBIC, uses the elapsed time (∆) since the last congestion event for calculating the current conges- tion window size. The window growth function of HTCP is a quadratic function of ∆. HTCP is unique in that it adjusts the decrease factor by a function of RTTs which is engineered to estimate the queue size in the network path of the current ﬂow. Thus, the decrease factor is adjusted to be proportional to the queue size.\\n\\nTCP-Vegas [10] measures the diﬀerence (δ) between expected throughput and actual throughput based on round-trip de- lays. When δ is less than a low threshold α, TCP-Vegas believes the path is not congested and thus increases the sending rate. When δ is larger than a upper threshold β, which is a strong indication of congestion, TCP-Vegas re- duces the sending rate. Otherwise, TCP-Vegas maintains the current sending rate. The expected throughput is cal- culated by dividing the current congestion window by the minimum RTT which typically contains the delay when the path is not congested. For each round trip time, TCP-Vegas computes the actual throughput by dividing the number of packets sent by the sampled RTT.\\n\\nFAST [24] determines the current congestion window size based on both round-trip delays and packet losses over a path. FAST updates the sending rate at every other RTT with rate-pacing. The algorithm estimates the queuing de- lay of the path using RTTs and if the delay is well below a threshold, it increases the window aggressively and if it gets closer to the threshold, the algorithm slowly reduces the increasing rate. The opposite happens when the delay increases beyond the threshold: slowly decreases the window ﬁrst and then aggressively decreases the window. For packet losses, FAST halves the congestion window and enters loss recovery just like TCP.\\n\\nTCP-Westwood [14] estimates an end-to-end available band-\\n\\nwidth by accounting the rate of returning ACKs. For packet losses, unlike TCP which “blindly” reduces the congestion window to the half, TCP-Westwood sets the slow start thresh- old to this estimate. This mechanism is eﬀective especially over wireless links where frequent channel losses are mis- interpreted as congestion losses and thus TCP reduces the congestion window unnecessarily.\\n\\nTCP-Illinois [26] uses a queueing delay to determine an in- crease factor α and multiplicative decrease factor β instan- taneously during the window increment phase. Precisely, TCP-Illinois sets a large α and small β when the average delay d is small, which is the indication that congestion is not imminent, and sets a small α and large β when d is large because of imminent congestion.\\n\\nTCP-Hybla [13] scales the window increment rule to ensure fairness among the ﬂows with diﬀerent RTTs. TCP-Hybla behaves as TCP-NewReno when the RTT of a ﬂow is less than a certain reference RTT (e.g., 20ms). Otherwise, TCP- Hybla increases the congestion window size more aggres- sively to compensate throughput drop due to RTT increase.\\n\\nTCP-Veno [17] determines the congestion window size very similar to TCP-NewReno, but it uses the delay information of TCP-Vegas to diﬀerentiate non-congestion losses. When packet loss happens, if the queue size inferred by the delay increase is within a certain threshold, which is the strong indication of random loss, TCP-Veno reduces the congestion window by 20%, not by 50%.\\n\\n3. CUBIC CONGESTION CONTROL 3.1 BIC-TCP In this section, we give some details on BIC-TCP which is a predecessor of CUBIC. The main feature of BIC-TCP is its unique window growth function as discussed in the introduc- tion. Figure 1 shows the growth function of BIC-TCP. When it gets a packet loss event, BIC-TCP reduces its window by a multiplicative factor β. The window size just before the reduction is set to the maximum Wmax and the window size just after the reduction is set to the minimum Wmin. Then, BIC-TCP performs a binary search using these two param- eters - by jumping to the “midpoint” between Wmax and Wmin. Since packet losses have occurred at Wmax, the win- dow size that the network can currently handle without loss must be somewhere between these two numbers.\\n\\nHowever, jumping to the midpoint could be too much in- crease within one RTT, so if the distance between the mid- point and the current minimum is larger than a ﬁxed con- stant, called Smax, BIC-TCP increments cwnd by Smax (lin- ear increase). If BIC-TCP does not get packet losses at the updated window size, that window size becomes the new minimum. This process continues until the window incre- ment is less than some small constant called Smin at which point, the window is set to the current maximum. So the growth function after a window reduction will be most likely to be a linear one followed by a logarithmic one (marked as “additive increase” and “binary search” respectively in Fig- ure 1 (a).)\\n\\nIf the window grows past the maximum, the equilibrium window size must be larger than the current maximum and a\\n\\n(a) BIC-TCP window growth function.\\n\\n(b) CUBIC window growth function.\\n\\nFigure 1: Window growth functions of BIC-TCP and CUBIC.\\n\\nnew maximum must be found. BIC-TCP enters a new phase called “max probing”. Max probing uses a window growth function exactly symmetric to those used in additive increase and binary search (which is logarithmic; its reciprocal will be exponential) and then additive increase. Figure 1 (a) shows the growth function during max probing. During max probing, the window grows slowly initially to ﬁnd the new maximum nearby, and after some time of slow growth, if it does not ﬁnd the new maximum (i.e., packet losses), then it guesses the new maximum is further away so it switches to a faster increase by switching to additive increase where the window size is incremented by a large ﬁxed increment. The good performance of BIC-TCP comes from the slow increase around Wmax and linear increase during additive increase and max probing.\\n\\n3.2 CUBIC window growth function BIC-TCP achieves good scalability in high speed networks, fairness among competing ﬂows of its own and stability with low window oscillations. However, BIC-TCP’s growth func- tion can still be too aggressive for TCP, especially under short RTT or low speed networks. Furthermore, the several diﬀerent phases (binary search increase, max probing, Smax and Smin) of window control add complexity in implement- ing the protocol and analyzing its performance. We have been searching for a new window growth function that while retaining strengths of BIC-TCP (especially, its stability and scalability), simpliﬁes the window control and enhances its TCP friendliness.\\n\\nWe introduce a new high-speed TCP variant: CUBIC. As the name of the protocol represents, the window growth function of CUBIC is a cubic function whose shape is very similar to the growth function of BIC-TCP. CUBIC uses a cubic function of the elapsed time from the last congestion event. While most alternative algorithms to Standard TCP uses a convex increase function where after a loss event, the\\n\\nwindow increment is always increasing, CUBIC uses both the concave and convex proﬁles of a cubic function for win- dow increase. Figure 1 (b) shows the growth function of CUBIC.\\n\\nThe details of CUBIC are as follows. After a window re- duction following a loss event, it registers Wmax to be the window size where the loss event occurred and performs a multiplicative decrease of congestion window by a factor of β where β is a window decrease constant and the regular fast recovery and retransmit of TCP. After it enters into conges- tion avoidance from fast recovery, it starts to increase the window using the concave proﬁle of the cubic function. The cubic function is set to have its plateau at Wmax so the con- cave growth continues until the window size becomes Wmax. After that, the cubic function turns into a convex proﬁle and the convex window growth begins. This style of window ad- justment (concave and then convex) improves protocol and network stability while maintaining high network utiliza- tion [12]. This is because the window size remains almost constant, forming a plateau around Wmax where network utilization is deemed highest and under steady state, most window size samples of CUBIC are close to Wmax, thus pro- moting high network utilization and protocol stability. Note that protocols with convex growth functions tend to have the largest window increment around the saturation point, introducing a large burst of packet losses.\\n\\nThe window growth function of CUBIC uses the following function:\\n\\nW(t) = C(t − K)3 + Wmax\\n\\nwhere C is a CUBIC parameter, t is the elapsed time from the last window reduction, and K is the time period that the above function takes to increase W to Wmax when there is no further loss event and is calculated by using the following equation:\\n\\nK =\\n\\n3\\n\\nr\\n\\nWmaxβ C\\n\\nUpon receiving an ACK during congestion avoidance, CU- BIC computes the window growth rate during the next RTT period using Eq. (1). It sets W(t + RTT) as the candidate target value of congestion window. Suppose that the cur- rent window size is cwnd. Depending on the value of cwnd, CUBIC runs in three diﬀerent modes. First, if cwnd is less than the window size that (standard) TCP would reach at time t after the last loss event, then CUBIC is in the TCP mode (we describe below how to determine this window size of standard TCP in term of time t). Otherwise, if cwnd is less than Wmax, then CUBIC is in the concave region, and if cwnd is larger than Wmax, CUBIC is in the convex region. Algorithm 1 shows the pseudo-code of the window adjustment algorithm of CUBIC implemented in Linux.\\n\\n3.3 TCP-friendly region When receiving an ACK in congestion avoidance, we ﬁrst check whether the protocol is in the TCP region or not. This is done as follows. We can analyze the window size of TCP in terms of the elapsed time t. Using a simple analysis in [16], we can ﬁnd the average window size of additive increase and multiplicative decrease (AIMD) with an additive factor\\n\\n(1)\\n\\n(2)\\n\\nAlgorithm 1: Linux CUBIC algorithm (v2.2)\\n\\nInitialization:\\n\\ntcp friendliness ←− 1, β ←− 0.2 fast convergence ←− 1, C ←− 0.4 cubic reset()\\n\\nOn each ACK: begin\\n\\nif dMin then dMin ←− min(dMin,RTT) else dMin ←− RTT if cwnd ≤ ssthresh then cwnd ←− cwnd + 1 else\\n\\ncnt ←− cubic update() if cwnd cnt > cnt then\\n\\ncwnd ←− cwnd + 1,cwnd cnt ←− 0\\n\\nelse cwnd cnt ←− cwnd cnt + 1\\n\\nend Packet loss: begin\\n\\nepoch start ←− 0 if cwnd < Wlast maxand fast convergence then\\n\\nWlast max ←− cwnd ∗ (2−β)\\n\\n2\\n\\n........................... (3.7)\\n\\nelse Wlast max ←− cwnd ssthresh ←− cwnd ←− cwnd∗(1−β) ................. (3.6)\\n\\nend Timeout: begin\\n\\ncubic reset()\\n\\nend cubic update(): .......................................................... (3.2) begin\\n\\nack cnt ←− ack cnt + 1 if epoch start ≤ 0 then\\n\\nepoch start ←− tcp time stamp if cwnd < Wlast max then\\n\\nK ←− 3 origin point ←− Wlast max q\\n\\nWlast max−cwnd C\\n\\nelse\\n\\nK ←− 0 origin point ←− cwnd\\n\\nack cnt ←− 1 Wtcp ←− cwnd\\n\\nt ←− tcp time stamp + dMin − epoch start target ←− origin point + C(t − K)3 if target > cwnd then cnt ←− else cnt ←− 100 ∗ cwnd if tcp friendliness then cubic tcp friendliness()\\n\\ncwnd\\n\\ntarget−cwnd .. (3.4,3.5)\\n\\nend cubic tcp friendliness(): .......................................... (3.3) begin\\n\\nWtcp ←− Wtcp + 3β ack cnt ←− 0 if Wtcp > cwnd then max cnt ←− if cnt > max cnt then cnt ←− max cnt\\n\\n2−β ∗ ack cnt\\n\\ncwnd\\n\\ncwnd Wtcp−cwnd\\n\\nend cubic reset(): begin\\n\\nWlast max ←− 0, epoch start ←− 0, origin point ←− 0 dMin ←− 0, Wtcp ←− 0, K ←− 0, ack cnt ←− 0\\n\\nend\\n\\nα and a multiplicative factor β to be the following function:\\n\\n1 RTT s\\n\\nα 2\\n\\n2 − β β\\n\\n1 p\\n\\nBy the same analysis, the average window size of TCP with 1 α = 1 and β = 0.5 is p. Thus, for Eq. 3 to be the same as that of TCP, α must be equal to 3β q 2−β. If TCP increases its window by α per RTT, we can get the window size of TCP in terms of the elapsed time t as follows:\\n\\n1 RTT\\n\\n3 2\\n\\nWtcp(t) = Wmax(1 − β) + 3\\n\\nβ 2 − β\\n\\nt RTT\\n\\nIf cwnd is less than Wtcp(t), then the protocol is in the TCP mode and cwnd is set to Wtcp(t) at each reception of ACK. The cubic tcp friendliness() in Algorithm 1 describes this behavior.\\n\\n3.4 Concave region When receiving an ACK in congestion avoidance, if the pro- tocol is not in the TCP mode and cwnd is less than Wmax, then the protocol is in the concave region. In this region, cwnd is incremented by W(t+RTT)−cwnd , which is shown at (3.4) in Algorithm 1.\\n\\ncwnd\\n\\n3.5 Convex region When the window size of CUBIC is larger than Wmax, it passes the plateau of the cubic function after which CU- BIC follows the convex proﬁle of the cubic function. Since cwnd is larger than the previous saturation point Wmax, this indicates that the network conditions might have been perturbed since the last loss event, possibly implying more available bandwidth after some ﬂow departures. Since the Internet is highly asynchronous, ﬂuctuations in available bandwidth always exist. The convex proﬁle ensures that the window increases very slowly at the beginning and gradu- ally increases its growth rate. We also call this phase as the maximum probing phase since CUBIC is searching for a new Wmax. As we do not modify the window increase function only for the convex region, the window growth function for both regions remains unchanged. To be exact, if the pro- tocol is the convex region outside the TCP mode, cwnd is incremented by W(t+RTT)−cwnd , which is shown at (3.5) in Algorithm 1.\\n\\ncwnd\\n\\n3.6 Multiplicative decrease When a packet loss occurs, CUBIC reduces its window size by a factor of β. We set β to 0.2. A side eﬀect of setting β to a smaller value than 0.5 is slower convergence. We believe that while a more adaptive setting of β could result in faster convergence, it will make the analysis of the protocol much harder and also aﬀects the stability of the protocol. This adaptive adjustment of β is a future research issue.\\n\\n3.7 Fast Convergence To improve the convergence speed of CUBIC, we add a heuristic in the protocol. When a new ﬂow joins the net- work, existing ﬂows in the network need to give up their bandwidth shares to allow the new ﬂow some room for growth. To increase this release of bandwidth by existing ﬂows, we add the following mechanism called fast convergence.\\n\\n(3)\\n\\n(4)\\n\\nWith fast convergence, when a loss event occurs, before a window reduction of the congestion window, the protocol remembers the last value of Wmax before it updates Wmax for the current loss event. Let us call the last value of Wmax to be Wlast max. At a loss event, if the current value of Wmax is less than the last value of it, Wlast max, this in- dicates that the saturation point experienced by this ﬂow is getting reduced because of the change in available band- width. Then we allow this ﬂow to release more bandwidth by reducing Wmax further. This action eﬀectively lengthens the time for this ﬂow to increase its window because the re- duced Wmax forces the ﬂow to have the plateau earlier. This allows more time for the new ﬂow to catch up its window size. The pseudo code for this operation is shown at (3.7) in Algorithm 1.\\n\\n4. CUBIC IN LINUX KERNEL Since the ﬁrst release of CUBIC to the Linux community in 2006, CUBIC has gone through several upgrades. This section documents those changes.\\n\\n4.1 Evolution of CUBIC in Linux Table 1 summarizes important updates [1] on the implemen- tation of CUBIC in Linux since its ﬁrst introduction in Linux 2.6.13. The most updates on CUBIC are focussed on per- formance and implementation eﬃciency improvements. One of notable optimizations is the improvement on cubic root calculation. The implementation of CUBIC requires solving Eq. 2, a cubic root calculation. The initial implementation of CUBIC [18] in Linux uses the bisection method. But the Linux developer community worked together to replace it with the Newton-Rhaphson method which improves the running time by more than 10 times on average (1032 clocks vs. 79 clocks) and reduces the variance in running times. CUBIC also went through several algorithmic changes to have its current form to enhance its scalability, fairness and convergence speed.\\n\\n4.2 Pluggable Congestion Module More inclusions of TCP variants to the Linux kernel has substantially increased the complexity of the TCP code in the kernel. Even though a new TCP algorithm comes with a patch for the kernel, this process requires frequent kernel re- compilations and exacerbates the stability of the TCP code. To eliminate the need of kernel recompilation and help ex- perimenting with a new TCP algorithm with Linux, Stephen Hemminger introduces a new architecture [23, 6], called pluggable congestion module, in Linux 2.6.13. It is dynami- cally loadable and allows switching between diﬀerent conges- tion control algorithm modules on the ﬂy without recompi- lation. Figure 2 shows the interface to this module, named tcp congestion ops. Each method in tcp congestion ops is a hook in the TCP code that provides access to the TCP code. A new congestion control algorithm requires to deﬁne cong avoid and ssthresh, but the other methods are optional.\\n\\nThe init and release functions are called for the initializa- tion and termination of a given TCP algorithm. ssthresh is the slow start threshold which is called when the given TCP detects a loss. The lower bound on congestion window is the slow start threshold, but when congestion control needs to override this lower bound, min cwnd can be used for that\\n\\nstruct tcp_congestion_ops { ..\\n\\nvoid (*init)(struct sock *sk); void (*release)(struct sock *sk); u32 (*ssthresh)(struct sock *sk); u32 (*min_cwnd)(const struct sock *sk); void (*cong_avoid)(struct sock *sk, u32 ack,\\n\\nu32 in_flight);\\n\\nvoid (*set_state)(struct sock *sk, u8 new_state); void (*cwnd_event)(struct sock *sk,\\n\\nenum tcp_ca_event ev);\\n\\nu32 void (*pkts_acked)(struct sock *sk, u32 num_acked,\\n\\n(*undo_cwnd)(struct sock *sk);\\n\\ns32 rtt_us);\\n\\nvoid (*get_info)(struct sock *sk, u32 ext,\\n\\nstruct sk_buff *skb);\\n\\nchar\\n\\nname[TCP_CA_NAME_MAX];\\n\\n.. };\\n\\nFigure 2: tcp congestion ops structure\\n\\npurpose. cong avoid is called whenever an ACK arrives and the congestion window (cwnd) is adjusted. For instance, in standard TCP New-Reno, when an ACK arrives, cong avoid increments cwnd by one if the current cwnd is less than ssthresh (during slow start). Otherwise, cong avoid incre- ments cwnd by 1 cwnd (during congestion avoidance). set state is called when the congestion control state of TCP is changed among Normal, Loss Recovery, Loss Recovery after Time- out, Reordering, and Congestion Window Reduction. cwnd event is called when the events deﬁned in tcp ca event occur. When an algorithm requires to handle one of the events, it can create a hook to cwnd event which is called when the cor- responding event occurs. undo cwnd handles false detection of loss or timeout. When TCP realizes the change to cwnd is wrong, it falls back to the original cwnd using undo cwnd. pkts acked is a hook for counting ACKs; many protocols (e.g., BIC-TCP, CUBIC, and H-TCP) also use this hook to get RTT information. get info is a hook for providing congestion control information to the user space.\\n\\nCUBIC has been implemented as one of pluggable conges- tion control modules. The followings are the hooks that CUBIC use for its implementation [3].\\n\\n1. bictcp init:\\n\\ninitializes private variables used for CU- If initial ssthresh is not 0, then set BIC algorithm. ssthresh to this value. If initial ssthresh is properly set by users when there is no history information about the end-to-end path, it can improve the start-up be- havior of CUBIC signiﬁcantly.\\n\\n2. bictcp recalc ssthresh:\\n\\nIf the fast convergence mode is turned on and the current cwnd is smaller than last max, set last max to cwnd ∗ (1 − β 2). Otherwise, set last max to cwnd ∗ (1 − β). ssthresh is always set to cwnd ∗ (1 − β) because TCP needs to back oﬀ for congestion.\\n\\n3. bictcp cong avoid:\\n\\nincreases cwnd by computing the diﬀerence between the current cwnd value and its ex- pected value of the next RTT round which is obtained by cubic root calculation.\\n\\n4. bictcp set state: resets all the variables when a timeout happens.\\n\\n5. bictcp undo cwnd: returns the maximum between the current cwnd value and the last max (which is the con- gestion window before the drop).\\n\\n6. bictcp acked: maintains the minimum delay observed so far. The minimum delay is reset when a timeout happens.\\n\\n5. DISCUSSION With a deterministic loss model where the number of packets between two successive loss events is always 1 p, CUBIC al- ways operates with the concave window proﬁle which greatly simpliﬁes the performance analysis of CUBIC. The average window size of CUBIC can be obtained by the following function: (5)\\n\\nTo ensure fairness to Standard TCP based on our argument in the introduction, we set C to 0.4. We ﬁnd that this value of C allows the size of the TCP friendly region to be large enough to encompass most of the environments where Standard TCP performs well while preserving the scalability of the window growth function. With β set to 0.2, the above formula is reduced to the following function:\\n\\nE{Wcubic} = 1.17 4 ( r\\n\\nRTT p\\n\\n)3\\n\\n(6) is used to argue the fairness of CUBIC to Standard TCP and its safety for deployment below.\\n\\n5.1 Fairness to standard TCP In environments where standard TCP is able to make rea- sonable use of the available bandwidth, CUBIC does not signiﬁcantly change this state.\\n\\nStandard TCP performs well in the following two types of networks:\\n\\n1. networks with a small bandwidth-delay product (BDP). 2. networks with a short RTT, but not necessarily a small BDP.\\n\\nCUBIC is designed to behave very similarly to standard TCP in the above two types of networks. Figure 3 shows the response function (average window size) of standard TCP, HSTCP, and CUBIC. The average window size of standard TCP and HSTCP is from [15]. The average window size of CUBIC is calculated by using (6) and CUBIC TCP-friendly equation in (4). Figure 3 shows that CUBIC is more friendly to TCP than HSTCP, especially in networks with a short RTT where TCP performs reasonably well. For example, in a network with RTT = 10ms and p = 10−6, TCP has an average window of 1200 packets. If the packet size is 1500 bytes, then TCP can achieve an average rate of 1.44 Gbps. In this case, CUBIC achieves exactly the same rate as Standard TCP, whereas HSTCP is about ten times more aggressive than Standard TCP.\\n\\n(6)\\n\\n1e+06\\n\\nStandard TCP HSTCP CUBIC\\n\\n) s t e k c a p (\\n\\ne z S w o d n W\\n\\ni\\n\\ni\\n\\n100000\\n\\n10000\\n\\n1000\\n\\n. g v A\\n\\n100\\n\\n10\\n\\n1e-08\\n\\n1e-07\\n\\n1e-06\\n\\n1e-05\\n\\n0.0001\\n\\n0.001\\n\\n0.01\\n\\nRandom Loss Rate (packets)\\n\\n(a) Networks with 10ms RTT.\\n\\n1e+06\\n\\nStandard TCP HSTCP CUBIC\\n\\n) s t e k c a p (\\n\\n100000\\n\\ne z S w o d n W\\n\\ni\\n\\ni\\n\\n10000\\n\\n1000\\n\\n. g v A\\n\\n100\\n\\n10\\n\\n1e-08\\n\\n1e-07\\n\\n1e-06\\n\\n1e-05\\n\\n0.0001\\n\\n0.001\\n\\n0.01\\n\\nRandom Loss Rate (packets)\\n\\n(b) Networks with 100ms RTT.\\n\\nFigure 3: Response function of standard TCP, HSTCP, and CUBIC in networks with 10ms (a) and 100ms (b) RTTs respectively.\\n\\n5.2 CUBIC in action Figure 4 shows the window curve of CUBIC over the running time. This graph is obtained by running testbed experiment on a dumbbell network conﬁguration with signiﬁcant back- ground traﬃc in both directions. The bottleneck capacity is 400Mbps and the RTT is set to 240ms. Drop tail routers are used. There are two CUBIC ﬂows, and they have the same RTT and bottleneck. Note that the curves have plateaus around Wmax which is the window size at the time of the last packet loss event. We observe that two ﬂows use all phases of CUBIC functions over the running time and two ﬂows converges to a fair share within 200 seconds.\\n\\nFigure 5 shows the friendliness of CUBIC with respect to TCP-SACK. In this experiment, we run one CUBIC ﬂow with one TCP-SACK ﬂow over a short-RTT network path (8ms) and a long-RTT network path (82ms), respectively. Under the short-RTT (8ms) network where even TCP-SACK can use the full bandwidth of the path, CUBIC operates in the TCP-friendly mode. Figure 5 (a) conﬁrms that one CU- BIC ﬂow runs in the TCP-friendly mode and shares the bandwidth fair with the other TCP-SACK ﬂow by main- taining the congestion window of CUBIC similar with that of TCP-SACK. Under the long-RTT (82ms) network where Standard TCP has the under-utilization problem, CUBIC uses a cubic function to be scalable for this environment. Figure 5 (b) conﬁrms that the CUBIC ﬂow runs a cubic win- dow growth function unlike the case with the short-RTT net-\\n\\n0.1\\n\\n0.1\\n\\n18000\\n\\nFast Convergence\\n\\n16000\\n\\n14000\\n\\n12000\\n\\n) s t e k c a p (\\n\\n10000\\n\\n8000\\n\\nConcave Growth\\n\\n6000\\n\\nConvex Growth\\n\\n4000\\n\\n2000\\n\\nMultiplicative DecreaseCUBIC flow1 CUBIC flow2\\n\\n0\\n\\n0\\n\\n100\\n\\n200\\n\\n300\\n\\n400\\n\\n500\\n\\nTime (second)\\n\\n(a) CUBIC window curves.\\n\\n400\\n\\n350\\n\\n300\\n\\n250\\n\\n) s p b M\\n\\n200\\n\\n(\\n\\n150\\n\\n100\\n\\n50\\n\\nCUBIC flow1 CUBIC flow2\\n\\n0\\n\\n0\\n\\n100\\n\\n200\\n\\n300\\n\\n400\\n\\n500\\n\\nTime (second)\\n\\n(b) Throughput of two CUBIC ﬂows.\\n\\nFigure 4: Two CUBIC ﬂows with 246ms RTT.\\n\\nwork where CUBIC is indistinguishable with TCP-SACK.\\n\\nFigure 6 shows the experiment with four TCP-SACK ﬂows and four CUBIC ﬂows. For this experiment, we set the bandwidth to 400Mbps, RTT to 40ms, and buﬀer size to 100% BDP of a ﬂow. We observe that four ﬂows of CUBIC converge to a fair share nicely within a short period of time. Their cwnd curves are very smooth and do not cause much disturbance to competing TCP ﬂows. In this experiment, the total network utilization is around 95%: the four CUBIC ﬂows take about 72% of the total bandwidth, the four TCP ﬂows take 23%.\\n\\n6. EXPERIMENTAL EVALUATION 6.1 Experimental Setup We construct a dumbbell topology shown in Figure 7 where two dummynet routers are located at the bottleneck between two end points. Each end points consists of a set of Dell Linux servers dedicated to high-speed TCP variant ﬂows and background traﬃc. Background traﬃc is generated by us- ing a modiﬁcation of a web-traﬃc generator, called Surge [9] and Iperf [2]. We modiﬁed Surge to generate a wider range of ﬂow sizes in order to increase variability in cross traﬃc because medium size ﬂows tend to fully execute the slow start and increase the variability in available bandwidth. The RTT of each background traﬃc is randomly selected from an exponential distribution found in [7]. The socket buﬀer size of background traﬃc machines is ﬁxed to de- fault 64KB while high-speed TCP machines are conﬁgured to have a very large buﬀer so that the transmission rates of high-speed ﬂows are only limited by the congestion con- trol algorithm. Two dummynet routers and four high-speed TCP machines are tuned to generate or forward traﬃc close to 1Gbps. The details of system tuning for both Linux and\\n\\n600\\n\\n600\\n\\n500\\n\\n450\\n\\nTCP-SACK CUBIC\\n\\n400\\n\\n350\\n\\n) s t e k c a p (\\n\\n300\\n\\n250\\n\\nTCP-Friendly Region\\n\\n200\\n\\n150\\n\\n100\\n\\n50\\n\\n0\\n\\n100\\n\\n200\\n\\n300\\n\\n400\\n\\n500\\n\\n600\\n\\nTime (second) (a) RTT 8ms.\\n\\n6000\\n\\nTCP-SACK CUBIC\\n\\n5000\\n\\n4000\\n\\n) s t e k c a p (\\n\\n3000\\n\\n2000\\n\\n1000\\n\\n0\\n\\n0\\n\\n100\\n\\n200\\n\\n300\\n\\n400\\n\\n500\\n\\n600\\n\\nTime (second) (b) RTT 82ms.\\n\\nFigure 5: One CUBIC ﬂow and one TCP-SACK ﬂow. Bandwidth is set to 400Mbps.\\n\\n) s t e k c a p (\\n\\n2500\\n\\n2000\\n\\n1500\\n\\n1000\\n\\nTCP-SACK flow1 TCP-SACK flow2 TCP-SACK flow3 TCP-SACK flow3 CUBIC flow1 CUBIC flow2 CUBIC flow3 CUBIC flow4\\n\\n500\\n\\n0\\n\\n0\\n\\n100\\n\\n200\\n\\n300\\n\\n400\\n\\n500\\n\\n600\\n\\nTime (second)\\n\\nFigure 6: Four TCP-SACK ﬂows and four CUBIC ﬂows over 40ms RTT\\n\\nFreeBSD systems are shown in [5]. Note that Netem [22] in Linux provides the same functionality with the dummynet software in FreeBSD. For this experiment, the maximum bandwidth of the bottleneck router is set to 400Mbps. The bottleneck buﬀer size is set to 100% BDP if it is not explic- itly speciﬁed. The amount of background traﬃc comparable to around 15% of the bottleneck bandwidth is pushed into forward and backward directions of the dumbbell. We use the drop-tail router at the bottleneck.\\n\\n6.2 Intra-Protocol Fairness We measure the intra-protocol fairness between two ﬂows of a protocol with the same RTT. We use a throughput ratio between these two ﬂows for representing the intra- protocol fairness. This metric represents a degree of band- width shares between two ﬂows of the same protocol. For this experiment, we vary RTTs between 16ms and 324ms and test CUBIC, BIC-TCP, HSTCP, and TCP-SACK pro-\\n\\nFigure 7: Testbed\\n\\ntocols. Figure 8 (a) and 8 (b) show the intra-protocol fair- ness and link utilization for the tested protocols. CUBIC and BIC-TCP show higher fairness index than TCP-SACK and HSTCP, representing better fair sharing between the ﬂows. With 16ms RTT, TCP-SACK shows the best fairness index indicating that Standard TCP works fairly well un- der small RTT networks. CUBIC, BIC-TCP, and HSTCP utilize the link regardless of RTTs while TCP-SACK suﬀers under-utilization with larger RTTs.\\n\\n6.3 Inter-RTT Fairness We measure the fairness in sharing the bottleneck band- width between two competing ﬂows that have diﬀerent RTTs. For this experiment, we ﬁx RTT of one ﬂow to 162ms and vary RTT of the other ﬂow between 16ms and 164ms. This setting gives us the RTT ratio up to 10. We test CU- BIC, BIC-TCP, HSTCP, and TCP-SACK protocols. Fig- ure 9 (a) shows that TCP-SACK achieves RTT fairness lin- early proportional to the inverse of the RTT ratio, which means that the short RTT ﬂow has proportionally more bandwidth shares than the longer RTT ﬂow. Even though there is no commonly accepted notion of RTT-fairness, we think the proportional fairness of TCP-SACK is desirable because long RTT ﬂows tend to use more resources along the longer path than short RTT ﬂows. But some of high- speed protocols are desiged to provide an equal bandwidth sharing among the ﬂows with diﬀerent RTTs (e.g., H-TCP and FAST). Based on this notion of RTT fairness, if the RTT fairness of a protocol has a similar slope with TCP- SACK, we can say the protocol is “acceptable”. Figure 9 (a) conﬁrms that CUBIC has a similar slope with TCP- SACK but with a higher fairness ratio indicating better share of resources (bandwidth) while HSTCP fails in achiev- ing a similar slope. Even though BIC-TCP shows the simi- lar slope with TCP-SACK, it shows the lowest fairness ra- tios among tested protocols. This is what CUBIC improves over BIC-TCP for RTT-fairness. We also observe that even though two HSTCP ﬂows fully utilize the link regardless of their RTT ratio (See Figure 9 (b)), the slow convergence of HSTCP ﬂows hinders even two ﬂows of the same RTT from reaching to a fair share within a reasonable amount of time.\\n\\n6.4 Impact on standard TCP trafﬁc As many new high-speed TCP protocols modify the win- dow growth function of TCP in a more scalable fashion,\\n\\n1\\n\\n0.9\\n\\no i t a R\\n\\n0.8\\n\\nt u p h g u o r h T\\n\\n0.7\\n\\n0.6\\n\\n0.5\\n\\nTCP-SACK HSTCP BIC-TCP CUBIC\\n\\n0.4\\n\\n0\\n\\n50\\n\\n100\\n\\n150\\n\\n200\\n\\n250\\n\\n300\\n\\nRTT (ms)\\n\\n(a) Intra-Protocol Fairness.\\n\\n100\\n\\n90\\n\\nn o i t a z\\n\\n80\\n\\ni l i t\\n\\nU k n L\\n\\ni\\n\\n70\\n\\n60\\n\\n50\\n\\nTCP-SACK HSTCP BIC-TCP CUBIC\\n\\n40\\n\\n0\\n\\n50\\n\\n100\\n\\n150\\n\\n200\\n\\n250\\n\\n300\\n\\nRTT (ms)\\n\\n(b) Link Utilization.\\n\\nFigure 8: Intra-protocol fairness (a) and link uti- lization (b). The bottleneck bandwidth is set to 400Mbps and 2Mbyte bottleneck buﬀer is used. RTT is varied between 16ms and 324ms and two ﬂows have the same RTT.\\n\\nthese new protocols tend to aﬀect the performance of Stan- dard TCP ﬂows which share the same bottleneck link along the path. As being fair to Standard TCP is critical to the safety of the protocol, we need to make sure that the window growth function of a new protocol does not unfairly aﬀect the Standard TCP ﬂows.\\n\\nIn this experiment, we measure how much these high-speed protocols steal the bandwidth from competing TCP-SACK ﬂows. By following the scenarios shown in the recent eval- uation proposal [8], we ﬁrst measure the throughput shares of four TCP-SACK ﬂows when they are competing with the other four TCP-SACK ﬂows. After that, we replace four ﬂows with a new protocol. We measure the share of TCP-SACK ﬂows and the other four TCP variant ﬂows at each run and report only the accumulated average of their bandwidth shares. We test CUBIC, BIC-TCP, HSTCP, and TCP-SACK.\\n\\nFigure 10 (a) shows the relationship between RTT and the throughput share between a new protocol ﬂows and TCP- SACK ﬂows. We ﬁx the bottleneck bandwidth to 400Mbps and vary RTT between 10ms and 160ms. Clearly, TCP- SACK ﬂows do not fully utilize the bottleneck bandwidth as RTT increases due to its slow window growth function. With 400Mbps and 160ms RTT, 8 TCP-SACK ﬂows achieve around 80% of the link bandwidth, but the underutilization will be very serious for larger BDP path and with small num- ber of ﬂows. CUBIC, BIC-TCP, and HSTCP fully utilize the link, thanks to their scalable window growth functions. All\\n\\n350\\n\\n350\\n\\n1\\n\\n0.8\\n\\no i t a R\\n\\n0.6\\n\\nt u p h g u o r h T\\n\\n0.4\\n\\n0.2\\n\\nTCP-SACK HSTCP BIC-TCP CUBIC\\n\\n0\\n\\n0\\n\\n20\\n\\n40\\n\\n60\\n\\n80\\n\\n100\\n\\n120\\n\\n140\\n\\n160\\n\\nRTT (ms)\\n\\n(a) Inter-RTT Fairness.\\n\\n100\\n\\n90\\n\\nn o i t a z\\n\\n80\\n\\ni l i t\\n\\nU k n L\\n\\ni\\n\\n70\\n\\n60\\n\\n50\\n\\nTCP-SACK HSTCP BIC-TCP CUBIC\\n\\n40\\n\\n0\\n\\n20\\n\\n40\\n\\n60\\n\\n80\\n\\n100\\n\\n120\\n\\n140\\n\\n160\\n\\nRTT (ms)\\n\\n(b) Link Utilization.\\n\\nFigure 9: Inter-RTT fairness. The bottleneck band- width is set to 400Mbps and 2Mbyte buﬀer is used. One ﬂow has a ﬁxed RTT of 162ms and the other ﬂow varies its RTT from 16ms to 162ms.\\n\\nthe tested high-speed protocols grab more bandwidth share from TCP-SACK as RTT increases. Also we conﬁrm that CUBIC gives more room to TCP-SACK than BIC-TCP and HSTCP for whole range of tested RTTs while achieving full utilization of the path. This is one of the design objective of CUBIC that it operates like BIC-TCP and be nice to other ﬂows in the network. As RTT increases, CUBIC, BIC-TCP and HSTCP steal more bandwidth from TCP-SACK. Some amount of bandwidth they steal is from the amount of band- width that TCP-SACK doesn’t utilize.\\n\\nFigure 10 (b) and 10 (c) show the performance results re- garding the TCP friendliness over short-RTT networks (10ms RTT) and long-RTT networks (100ms RTT), respectively. According to [15], under high loss rate regions (small-RTT networks) where TCP is well-behaving, the protocol must behave like TCP, and under low loss rate regions (large- RTT networks) where TCP has a low utilization problem, it can use more bandwidth than TCP. As shown in Fig- ure 10 (b), with 10ms RTT, we can see that TCP-SACK still uses the full bandwidth. In this region, all high-speed protocols need to be friendly to TCP-SACK by following the arguments above. Interestingly, CUBIC behaves more TCP- friendly even comparing to TCP-SACK for certain band- widths. Rather than stealing the bandwidth from TCP- SACK ﬂows, CUBIC ﬂows employs a window growth func- tion that is comparable to TCP-SACK, so that competing TCP-SACK ﬂows have the same chance with CUBIC ﬂows for grabbing the bandwidth shares. However, BIC-TCP and HSTCP show a tendency to operate in a scalable mode (being more aggressive) as the link speed increases. Even\\n\\n180\\n\\n180\\n\\nthough the graph doesn’t show the results corresponding to the link speed beyond 400Mbps, it is obvious that a scalable mode of BIC-TCP and HSTCP will deprive most of band- width share of TCP-SACK. As most high-speed TCP pro- tocols including BIC-TCP and HSTCP achieve TCP friend- liness by having some form of “TCP modes” during which they behave in the same way as TCP. BIC-TCP and HSTCP enter their TCP mode when the window size is less than 14 and 38 packets, respectively. Therefore, even with 1ms RTT, if BDP is larger than 38 packets, HSTCP will operate in a scalable mode. This is the limitation when the protocol uses a ﬁxed cutoﬀ for detecting a TCP-friendly region. CU- BIC deﬁnes a TCP-friendly region in real-time; therefore, CUBIC doesn’t have this scalability problem.\\n\\nFigure 10 (c) shows the results with 100ms RTT. All four protocols show reasonable friendliness to TCP. As the band- width gets larger than 10Mbps, the throughput ratio drops quite rapidly. As CUBIC, like BIC-TCP and HSTCP, re- gards this operating region is out of TCP-friendly region and behaves to be scalable to this environment. CUBIC and BIC-TCP show a similar aggressiveness which is slightly more aggressive† than HSTCP especially for the bandwidth less than 100Mbps. Through an extensive testing [4], we conﬁrm that this doesn’t highly impact on the performance of TCP-SACK.\\n\\n7. CONCLUSION We propose a new TCP variant, called CUBIC, for fast and long distance networks. CUBIC is an enhanced ver- sion of BIC-TCP. It simpliﬁes the BIC-TCP window control and improves its TCP-friendliness and RTT-fairness. CU- BIC uses a cubic increase function in terms of the elapsed time since the last loss event. In order to provide fairness to Standard TCP, CUBIC also behaves like Standard TCP when the cubic window growth function is slower than Stan- dard TCP. Furthermore, the real-time nature of the pro- tocol keeps the window growth rate independent of RTT, which keeps the protocol TCP friendly under both short and long RTT paths. We show the details of Linux CUBIC algorithm and implementation. Through extensive testing, we conﬁrm that CUBIC tackles the shortcomings of BIC- TCP and achieves fairly good Intra-protocol fairness, RTT- fairness and TCP-friendliness.\\n\\n8. REFERENCES [1] Git logs for CUBIC updates.\\n\\nhttp://git.kernel.org/?p=linux/kernel/git/davem/net- 2.6.git;a=history;f=net/ipv4/tcp cubic.c; h=eb5b9854c8c7330791ada69b8c9e8695f7a73f3d;hb=HEAD.\\n\\n[2] Iperf. http://sourceforge.net/projects/iperf .\\n\\n[3] Linux CUBIC source navigation.\\n\\nhttp://lxr.linux.no/linux/net/ipv4/tcp cubic.c.\\n\\n[4] TCP Testing Wiki.\\n\\nhttp://netsrv.csc.ncsu.edu/wiki/index.php/TCP Testing.\\n\\n†We used the latest update of CUBIC (v2.2) which improved the scalability and convergence speed of the protocol, which doesn’t clamp the increment in both convex and cocave re- gions. A slight increase of aggressivenss is the trade-oﬀ be- tween scalability and TCP-friendlines. Our extensive testing conﬁrms that CUBIC has better scalability and convergence speed with this small change (trade-oﬀ) while obtaining rea- sonable TCP-friendliness.\\n\\n450\\n\\n400\\n\\nSACK SACK HSTCP BIC-TCP CUBIC\\n\\n350\\n\\n) s p b M\\n\\n300\\n\\n250\\n\\nu p h g u o r h T\\n\\n200\\n\\n150\\n\\n100\\n\\n50\\n\\n0\\n\\n10\\n\\n20\\n\\n40\\n\\n80\\n\\n160\\n\\nRTT (ms)\\n\\n(a) Bandwidth 400Mbps with varying RTT\\n\\n120\\n\\n100\\n\\nSACK SACK HSTCP BIC-TCP CUBIC\\n\\n80\\n\\n%\\n\\nn o\\n\\ni t\\n\\na z\\n\\n60\\n\\ni l i t\\n\\nU k n L\\n\\ni\\n\\n40\\n\\n20\\n\\n0\\n\\n10\\n\\n50\\n\\n100\\n\\n200\\n\\n400\\n\\nLink Speed (Mbps)\\n\\n(b) RTT 10ms with varying bandwidth\\n\\n120\\n\\n100\\n\\nSACK SACK HSTCP BIC-TCP CUBIC\\n\\n80\\n\\n%\\n\\nn o i t a z\\n\\ni l i t\\n\\n60\\n\\nU k n L\\n\\ni\\n\\n40\\n\\n20\\n\\n0\\n\\n10\\n\\n50\\n\\n100\\n\\n200\\n\\n400\\n\\nLink Speed (Mbps)\\n\\n(c) RTT 100ms with varying bandwidth\\n\\nFigure 10: Impact on standard TCP traﬃc.\\n\\n[5] Testing setup for Linux and FreeBSD.\\n\\nhttp://netsrv.csc.ncsu.edu/wiki/index.php/ Testing Setup of kernel 2.6.23.9.\\n\\n[6] Pluggable congestion avoidance modules. http://lwn.net/Articles/128681/ (2005).\\n\\n[7] Aikat, J., Kaur, J., Smith, F., and Jeffay, K.\\n\\nVariability in TCP round-trip times. In Proceedings of the ACM SIGCOMM Internet Measurement Conference (Miami, FL, October 2003).\\n\\n[8] Andrew, L., Marcondes, C., Floyd, S., Dunn, L.,\\n\\nGuillier, R., Gang, W., Eggert, L., Ha, S., and Rhee, I. Towards a common TCP evaluation suite. In Proceedings of the fourth PFLDNet Workshop (UK, March 2008).\\n\\n[9] Barford, P., and Crovella, M. Generating\\n\\nrepresentative web workloads for network and server performance evaluation. In Measurement and Modeling of Computer Systems (1998), pp. 151–160.\\n\\n[10] Brakmo, L., and Peterson, L. TCP vegas: End to end\\n\\ncongestion avoidance on a global internet. IEEE Journal of\\n\\nSelected Areas in Communications (October 1995). [11] Bullot, H., Cottrell, R. L., and Hughes-Jones, R.\\n\\nEvaluation of advanced TCP stacks on fast long-distance production networks. In Proceedings of the third PFLDNet Workshop (Illinois, February 2004).\\n\\n[12] Cai, H., Eun, D., Ha, S., Rhee, I., and Xu, L. Stochastic\\n\\nordering for internet congestion control and its applications. In Proceedings of IEEE INFOCOM (Anchorage, Alaska, May 2007).\\n\\n[13] Caini, C., and Firrincieli, R. TCP hybla: a TCP\\n\\nenhancement for heterogeneous networks. International Journal of Satellite Communication and Networking 22, 5 (September 2004), 547–566.\\n\\n[14] Casetti, C., Gerla, M., Mascolo, S., Sanadidi, M. Y., and Wang, R. TCP Westwood: Bandwidth estimation for enhanced transport over wireless links. In Proceedings of ACM Mobicom (Rome, Italy, July 2001).\\n\\n[15] Floyd, S. HighSpeed TCP for Large Congestion Windows.\\n\\nRFC 3649 (Experimental), Dec. 2003.\\n\\n[16] Floyd, S., Handley, M., and Padhye, J. A Comparison\\n\\nof Equation-Based and AIMD Congestion Control, May 2000.\\n\\n[17] Fu, C. P., and Liew, S. C. TCP Veno: TCP Enhancement for Transmission Over Wireless Access Networks. IEEE Journal of Selected Areas in Communications (Feb 2003).\\n\\n[18] Ha, S. Cubic v2.0-pre patch.\\n\\nhttp://netsrv.csc.ncsu.edu/twiki/pub/Main/BIC/cubic- kernel-2.6.13.patch.\\n\\n[19] Hatano, T., Fukuhara, M., Shigeno, H., and Okada, K. TCP-friendly SQRT TCP for High Speed Networks. In Proceedings of APSITT (November 2003), pp. 455–460.\\n\\n[20] Hemminger, S. Cubic root benchmark code.\\n\\nhttp://lkml.org/lkml/2007/3/13/331.\\n\\n[21] Hemminger, S. Linux TCP Performance Improvements.\\n\\nLinux World 2004 (2004).\\n\\n[22] Hemminger, S. Network Emulation with NetEm. Linux\\n\\nConf Au (2005).\\n\\n[23] Hemminger, S. TCP infrastructure split out. http://lwn.net/Articles/128626/ (2005).\\n\\n[24] Jin, C., Wei, D. X., and Low, S. H. FAST TCP:\\n\\nmotivation, architecture, algorithms, performance. In Proceedings of IEEE INFOCOM (Hong Kong, March 2004).\\n\\n[25] Kelly, T. Scalable TCP: Improving performance in\\n\\nhighspeed wide area networks. ACM SIGCOMM Computer Communication Review 33, 2 (April 2003), 83–91.\\n\\n[26] Liu, S., Basar, T., and Srikant, R. TCP-Illinois: A loss\\n\\nand delay-based congestion control algorithm for high-speed networks. In Proceedings of VALUETOOLS (Pisa, Italy, October 2006).\\n\\n[27] Rhee, I., and Xu, L. CUBIC: A new TCP-friendly high-speed TCP variant. In Proceedings of the third PFLDNet Workshop (France, February 2005). [28] Shorten, R. N., and Leith, D. J. H-TCP: TCP for\\n\\nhigh-speed and long-distance networks. In Proceedings of the Second PFLDNet Workshop (Argonne, Illinois, February 2004).\\n\\n[29] Tarreau, W. Cubic optimization.\\n\\nhttp://git.kernel.org/?p=linux/kernel/git/davem/net- 2.6.git;a=commit;h=7e58886b45bc4a309aeaa8178ef89ﬀ767daaf7f .\\n\\n[30] Xu, L., Harfoush, K., and Rhee, I. Binary increase congestion control for fast long-distance networks. In Proceedings of IEEE INFOCOM (Hong Kong, March 2004).\\n\\n[31] Zhang, Y., Duffield, N., Paxson, V., and Shenker, S.\\n\\nOn the constancy of Internet path properties. In Proceedings of ACM SIGCOMM Internet Measurement Workshop (November 2001).\\n\\nVersion 2.0-pre\\n\\n2.0\\n\\n2.1\\n\\n2.2\\n\\nKernel 2.6.13\\n\\nUpdates The authors releases the ﬁrst CUBIC implementation in Linux to the Linux community [18].\\n\\n2.6.15\\n\\nCUBIC is oﬃcially included in the Linux kernel.\\n\\n2.6.18\\n\\nCUBIC replaces BIC-TCP as the de- fault TCP protocol in Linux kernel.\\n\\n2.6.19\\n\\nThe original implementation of CUBIC has a scaling bug. It has taken about a month to ﬁx this bug since CUBIC replaced BIC-TCP.\\n\\n2.6.21\\n\\nIts original implementation by the au- thors are optimized by the Linux de- veloper for better performance [20, 29]. In particular, the cubic root calculation in CUBIC, originally implemented in the bisection method, is now replaced by a Newton-Raphson method with ta- ble loopups for small values. This re- sults in more than 10 times perfor- mance improvement in the cubic root calculation. On average, the bisection method costs 1032 clocks while the im- proved version costs only 79 clocks.\\n\\n2.6.22\\n\\nimplementation of CU- The original BIC clamped the maximum window in- crement to 32 packets per RTT. This feature is inherited from BIC-TCP (Smax). An extensive lab testing con- ﬁrmed that CUBIC can safely remove this window clamping in the concave region. This enhances the scalability of CUBIC over very large BDP network paths. This is incorporated in CUBIC 2.1 (Linux 2.6.22).\\n\\n2.6.22-rc4 CUBIC improves slow start for fast\\n\\nstart-up by removing initial ssthresh.\\n\\n2.6.23\\n\\nThe use of received timestamp op- tion value from RTT calculation is removed for preventing possible ma- licious receiver attacks that reports wrong timestamps to reduce RTTs for more throughput.\\n\\n2.6.25-rc3 The window clamping during the con- vex growth phase is also removed. This feature allows CUBIC to improve its convergence speed while maintaining its fairness and TCP friendliness.\\n\\nTable 1: CUBIC version history')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f515a23-e265-4cc2-8502-ff4fe0c75699",
   "metadata": {},
   "source": [
    "Each document object contains metadata, such as the document title, as well as the raw text."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fab1399e-9c12-4ab4-9554-b86b4aac2d00",
   "metadata": {},
   "source": [
    "### Creating a Vector Store"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72d5cf8f-f132-459b-aed9-fc4825c8fd42",
   "metadata": {},
   "source": [
    "Now that we have extracted the text from the PDFs, we must further process our data so that it can be efficiently searched by our pipeline. We will do this by saving our documents into a **vector store**.\n",
    "\n",
    "#### Chunking\n",
    "\n",
    "The vectors will be created using an embedding model, but before we do this, we must **chunk** our documents. We have to do this because embedding models have a context limit, and some of our documents are too large to fit into a single vector. For example, the embedding model that we're using, `bge-m3`, has a context limit of 8,000 tokens (per its [datasheet](https://ollama.com/library/bge-m3)).\n",
    "\n",
    "How you chunk your documents is important because each chunk should represent a coherent idea that reflects the intended meaning from the original document. If your chunks are too large, you risk feeding your pipeline unnecessary or only tangentially relevant information. If your chunks are too small, then you may lose essential context that helps the retriever and model understand what a chunk is actually about. Consider this example:\n",
    "\n",
    "> Red squirrels have a varied and adaptable diet that changes with the seasons. They primarily eat seeds from conifer cones, such as pine, spruce, and fir, carefully stripping the cones to reach the nutritious seeds inside. In addition to seeds, they consume nuts, berries, fruits, buds, and fungi, especially mushrooms. Red squirrels are also known to occasionally eat insects, bird eggs, or nestlings when plant food is scarce.\n",
    "\n",
    "> Red squirrels typically live in forests dominated by coniferous or mixed trees, which provide both food and shelter. They build nests, called dreys, high in the trees using twigs, leaves, moss, and bark for insulation. Some individuals also use hollow trees or abandoned woodpecker holes for nesting. Their habitat usually includes well-defined territories that they actively defend from other squirrels.\n",
    "\n",
    "If we combine both paragraphs into a single chunk, then a query about the diet of red squirrels will retrieve information about their habitat and nesting behavior as well. While this information is related, it is not directly relevant to the question being asked. As a result, the retrieved context may fill up the model’s context window more quickly and crowd out other, more relevant chunks from different documents.\n",
    "\n",
    "On the other hand, if we split the document too aggressively (e.g., by making each sentence into its own chunk), then the sentences' original context is lost. Important information that is implicit in the surrounding sentences may no longer be available to the retriever. For example, if a user asks, \"What do red squirrels eat?\", the retriever may fail to identify the following sentence as relevant:\n",
    "\n",
    "> They primarily eat seeds from conifer cones, such as pine, spruce, and fir, carefully stripping the cones to reach the nutritious seeds inside.\n",
    "\n",
    "On its own, this sentence does not explicitly mention red squirrels. Without the surrounding context, the retriever (and the model) has no clear signal that the sentence is describing the diet of red squirrels rather than some other animal.\n",
    "\n",
    "In this example, the best method would be to treat each paragraph as its own chunk, as each paragraph has a distinct topic.\n",
    "\n",
    "Of course, we cannot manually chunk every document. Instead, chunking tools allow us to specify chunk sizes, and also include chunk overlaps, which help avoid context loss. Here, I've specified 1200 characters, which is about the length of a short paragraph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e005b51b-f1c3-4494-a058-f84c79f49502",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 6 docs -> split into 39\n"
     ]
    }
   ],
   "source": [
    "chunk_size = 10000\n",
    "chunk_overlap = int(.2 * chunk_size)\n",
    "# separators=[\"\\n\\n\", \"\\n\", \". \", \" \", \"\"]\n",
    "separators=[\"\\n\\n\", \"\\n\", \". \"]\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=chunk_size, # Given in characters, not tokens (1 token = 3-4 characters)\n",
    "    chunk_overlap=chunk_overlap,\n",
    "    length_function=len,\n",
    "    separators=separators,\n",
    ")\n",
    "split_docs = text_splitter.split_documents(documents)\n",
    "print(f\"Loaded {len(documents)} docs -> split into {len(split_docs)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5813b4f8-bdfc-47d5-891d-a7631247dda5",
   "metadata": {},
   "source": [
    "After splitting, we have multiple documents, each representing a different chunk of each source:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ffc6f005",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUBIC-checkpoint.pdf\n",
      "CUBIC-checkpoint.pdf\n",
      "CUBIC-checkpoint.pdf\n",
      "CUBIC-checkpoint.pdf\n",
      "CUBIC-checkpoint.pdf\n",
      "CUBIC-checkpoint.pdf\n",
      "CUBIC-checkpoint.pdf\n",
      "BBR.pdf\n",
      "BBR.pdf\n",
      "BBR.pdf\n",
      "BBR.pdf\n",
      "BBR.pdf\n",
      "BBR.pdf\n",
      "CUBIC.pdf\n",
      "CUBIC.pdf\n",
      "CUBIC.pdf\n",
      "CUBIC.pdf\n",
      "CUBIC.pdf\n",
      "CUBIC.pdf\n",
      "CUBIC.pdf\n",
      "Hybla.pdf\n",
      "Hybla.pdf\n",
      "Hybla.pdf\n",
      "Hybla.pdf\n",
      "Hybla.pdf\n",
      "Hybla.pdf\n",
      "Hybla.pdf\n",
      "Hybla.pdf\n",
      "NewReno.pdf\n",
      "NewReno.pdf\n",
      "NewReno.pdf\n",
      "NewReno.pdf\n",
      "NewReno.pdf\n",
      "NewReno.pdf\n",
      "comparative_study.pdf\n",
      "comparative_study.pdf\n",
      "comparative_study.pdf\n",
      "comparative_study.pdf\n",
      "comparative_study.pdf\n"
     ]
    }
   ],
   "source": [
    "for doc in split_docs:\n",
    "    print(doc.metadata[\"source\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b031e72",
   "metadata": {},
   "source": [
    "#### Converting Chunks into Vectors\n",
    "\n",
    "The final step of data preparation is to convert our documents into \"vectors,\" which are numerical representations that capture the meaning of words, sentences, and passages. This allows the pipeline to efficiently run a similarity search with queries to extract contextually relevant documents.\n",
    "\n",
    "*How do we choose an embedding model?*\n",
    "\n",
    "The embedded documents get saved to a Chroma database (\"vector store\"):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "605a7a38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langchain_chroma.vectorstores.Chroma at 0x15436dd7ab40>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Chroma.from_documents(documents=split_docs,\n",
    "                      embedding=embeddings,\n",
    "                      persist_directory=VECTOR_STORE_PATH) # Specifying persist_directory saves the vector store as a file so we don't have to recreate it"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bae4005",
   "metadata": {},
   "source": [
    "Once the vector store has been saved to a file, you can read it using the following command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "aa0f3f22",
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_store = Chroma(persist_directory=VECTOR_STORE_PATH,\n",
    "                      embedding_function=embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6910fc6a-4753-4cbd-a4b2-adbbf51b9bfb",
   "metadata": {},
   "source": [
    "Now that we have a vector store, we can evaluate its ability to retrieve relevant information using similarity searches. For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "87f7397f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BBR.pdf (0.76)\n",
      "BBR.pdf (0.78)\n",
      "BBR.pdf (0.81)\n",
      "BBR.pdf (0.84)\n",
      "BBR.pdf (0.89)\n"
     ]
    }
   ],
   "source": [
    "def get_relevant_docs(query, vector_store):\n",
    "    results = vector_store.similarity_search_with_score(\n",
    "        query, k=5\n",
    "    )\n",
    "    for res, score in results:\n",
    "        print(res.metadata[\"source\"], f\"({round(score, 2)})\")\n",
    "\n",
    "query = \"How does BBR work?\"\n",
    "get_relevant_docs(query, vector_store)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ce66aed-09ce-4450-80d4-47c45688127e",
   "metadata": {},
   "source": [
    "Using a basic query, our retriever seems to work well. Let's try something more complex:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "66bf4f77-52c1-4112-a52c-e68f429b473d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BBR.pdf (0.77)\n",
      "Hybla.pdf (0.8)\n",
      "BBR.pdf (0.8)\n",
      "CUBIC-checkpoint.pdf (0.81)\n",
      "CUBIC.pdf (0.81)\n"
     ]
    }
   ],
   "source": [
    "query = \"Contrast the strategies used by CUBIC, Hybla, and BBR to handle connections with long Round Trip Times (RTT).\"\n",
    "get_relevant_docs(query, vector_store)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5e0bcdee-2626-413d-8bea-eddd61d5e133",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "comparative_study.pdf (0.74)\n",
      "comparative_study.pdf (0.78)\n",
      "comparative_study.pdf (0.8)\n",
      "comparative_study.pdf (0.84)\n",
      "comparative_study.pdf (0.87)\n"
     ]
    }
   ],
   "source": [
    "query = \"How do 'loss-based' protocols and 'delay-based' protocols struggle specifically in the context of Low-Earth-Orbit (LEO) satellite networks?\"\n",
    "get_relevant_docs(query, vector_store)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8ec85ce-5945-4060-85c0-8fb260280fff",
   "metadata": {},
   "source": [
    "## Running RAG"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db3f1d81",
   "metadata": {},
   "source": [
    "### Run an LLM locally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c00e7c55-9365-4734-8180-0ef152d5c5e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "MIT, or the Massachusetts Institute of Technology, is located in Cambridge, Massachusetts, United States. Specifically, its main campus is situated on a 168-acre site along the Charles River, adjacent to Boston and Harvard University.\n",
       "\n",
       "Here's the exact address:\n",
       "\n",
       "Massachusetts Institute of Technology\n",
       "77 Massachusetts Avenue\n",
       "Cambridge, MA 02139\n",
       "\n",
       "MIT also has other campuses and facilities located in nearby cities, including Cambridge, Boston, and Lexington, but its main campus is in Cambridge."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "llm = OllamaLLM(model=LLM_NAME, temperature=0.5)\n",
    "display(Markdown(llm.invoke(\"Where is MIT located?\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "bb135986-c1ae-4b25-ba4d-0437a22fd7cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**Getting Started with Pandas**\n",
       "=====================================\n",
       "\n",
       "Pandas is a powerful library for data manipulation and analysis in Python. Here's a step-by-step guide to get you started:\n",
       "\n",
       "### Installing Pandas\n",
       "\n",
       "First, make sure you have the latest version of Python installed on your system. Then, open a terminal or command prompt and run:\n",
       "```bash\n",
       "pip install pandas\n",
       "```\n",
       "This will install the `pandas` library.\n",
       "\n",
       "### Basic Usage\n",
       "\n",
       "Here's an example of creating a simple DataFrame (a 2-dimensional labeled data structure with columns of potentially different types):\n",
       "```python\n",
       "import pandas as pd\n",
       "\n",
       "# Create a dictionary with some sample data\n",
       "data = {'Name': ['John', 'Anna', 'Peter'],\n",
       "        'Age': [28, 24, 35],\n",
       "        'Country': ['USA', 'UK', 'Australia']}\n",
       "\n",
       "# Create a DataFrame from the dictionary\n",
       "df = pd.DataFrame(data)\n",
       "\n",
       "print(df)\n",
       "```\n",
       "Output:\n",
       "```\n",
       "     Name  Age    Country\n",
       "0    John   28         USA\n",
       "1    Anna   24          UK\n",
       "2   Peter   35  Australia\n",
       "```\n",
       "### Basic Operations\n",
       "\n",
       "Here are some basic operations you can perform on a DataFrame:\n",
       "\n",
       "* **Selecting columns**: `df['Name']` or `df[['Name', 'Age']]`\n",
       "* **Filtering rows**: `df[df['Age'] > 30]`\n",
       "* **Sorting data**: `df.sort_values(by='Age')`\n",
       "\n",
       "### Data Manipulation\n",
       "\n",
       "Pandas provides various functions for data manipulation, including:\n",
       "\n",
       "* **GroupBy**: group data by one or more columns and perform aggregation operations\n",
       "* **Merging**: combine two or more DataFrames based on a common column\n",
       "* **Reshaping**: change the shape of a DataFrame (e.g., from long to wide)\n",
       "\n",
       "Here's an example of using GroupBy:\n",
       "```python\n",
       "# Create another DataFrame with some sample data\n",
       "data2 = {'Name': ['John', 'Anna', 'Peter'],\n",
       "         'Age': [28, 24, 35],\n",
       "         'Country': ['USA', 'UK', 'Australia'],\n",
       "         'Score': [90, 80, 95]}\n",
       "\n",
       "df2 = pd.DataFrame(data2)\n",
       "\n",
       "# Group by Country and calculate the mean Score\n",
       "grouped_df = df2.groupby('Country')['Score'].mean()\n",
       "\n",
       "print(grouped_df)\n",
       "```\n",
       "Output:\n",
       "```\n",
       "Country\n",
       "Australia    95.0\n",
       "UK           80.0\n",
       "USA          90.0\n",
       "Name: Score, dtype: float64\n",
       "```\n",
       "### Data Analysis\n",
       "\n",
       "Pandas provides various functions for data analysis, including:\n",
       "\n",
       "* **Descriptive statistics**: `df.describe()`\n",
       "* **Correlation matrix**: `df.corr()`\n",
       "\n",
       "Here's an example of using descriptive statistics:\n",
       "```python\n",
       "# Calculate the mean, median, and standard deviation of Age\n",
       "print(df['Age'].describe())\n",
       "```\n",
       "Output:\n",
       "```\n",
       "count    3.000000\n",
       "mean     29.000000\n",
       "std      5.477225\n",
       "min      24.000000\n",
       "25%      27.500000\n",
       "50%      29.000000\n",
       "75%      30.500000\n",
       "max      35.000000\n",
       "Name: Age, dtype: float64\n",
       "```\n",
       "This is just a brief introduction to using Pandas in Python. I hope this helps you get started with data manipulation and analysis!"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(Markdown(llm.invoke(\"How do I use Pandas in Python?\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be523553",
   "metadata": {},
   "source": [
    "___\n",
    "\n",
    "### Set up the RAG pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c37b4783",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dynamic_prompt\n",
    "def prompt_with_context(request: ModelRequest) -> str:\n",
    "    \"\"\"Inject context into state messages.\"\"\"\n",
    "    last_query = request.state[\"messages\"][-1].text\n",
    "    retrieved_docs = vector_store.similarity_search(last_query, k=3)\n",
    "\n",
    "    docs_content = \"\\n\\n\".join(doc.page_content for doc in retrieved_docs)\n",
    "\n",
    "    # Print documents used:\n",
    "    print(\"\\nRetrieved documents:\") ##\n",
    "    for doc in retrieved_docs: ##\n",
    "        print(doc.metadata[\"source\"]) ##\n",
    "    print()\n",
    "\n",
    "    system_message = (\n",
    "        \"You are a helpful assistant. Answer only using the information from the following documents.\"\n",
    "        f\"\\n\\n{docs_content}\"\n",
    "    )\n",
    "\n",
    "    return system_message\n",
    "\n",
    "\n",
    "agent = create_agent(llm, tools=[], middleware=[prompt_with_context])\n",
    "\n",
    "def pose(query):\n",
    "    for step in agent.stream(\n",
    "        {\"messages\": [{\"role\": \"user\", \"content\": query}]},\n",
    "        stream_mode=\"values\",\n",
    "    ):\n",
    "        display(Markdown(step[\"messages\"][-1].text))\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf177d3f-75bc-4b28-b247-a8dc5cd4bb6c",
   "metadata": {},
   "source": [
    "Testing questions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "12fd7b93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "How do the design philosophies of BBR, CUBIC, and NewReno differ in their interpretation of network 'signals'?"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Retrieved documents:\n",
      "BBR.pdf\n",
      "BBR.pdf\n",
      "comparative_study.pdf\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "The design philosophies of BBR (Bottleneck Bandwidth and Round-trip time), CUBIC, and TCP NewReno differ in their interpretation of network \"signals\" or indicators that a congestion control algorithm uses to adjust its sending rate.\n",
       "\n",
       "**TCP NewReno:**\n",
       "\n",
       "* Interprets packet loss as the primary signal for congestion.\n",
       "* Assumes that packet loss is due to buffer overflow at routers, which indicates that the link bandwidth is fully utilized and the sender should reduce its rate.\n",
       "* Uses packet loss to trigger a reduction in the congestion window (CWND) and slow-start to recover from congestion.\n",
       "\n",
       "**CUBIC:**\n",
       "\n",
       "* Interprets packet loss as a signal for congestion, but also considers other factors such as packet delay and jitter.\n",
       "* Aims to fill up the link bandwidth without building up a queue, similar to TCP Vegas.\n",
       "* Uses a more aggressive approach than NewReno, increasing the CWND faster in response to available bandwidth.\n",
       "\n",
       "**BBR (Bottleneck Bandwidth and Round-trip time):**\n",
       "\n",
       "* Interprets network \"signals\" as the bottleneck bandwidth and round-trip time (RTT) of the network path.\n",
       "* Aims to fill up the link bandwidth without building up a queue, but does so by frequently probing the network for its minimal RTT and bottleneck bandwidth.\n",
       "* Adjusts the TCP sending rate to match the bandwidth-delay product, which is calculated based on the observed bottleneck bandwidth and RTT.\n",
       "\n",
       "In summary:\n",
       "\n",
       "* NewReno focuses on packet loss as the primary signal for congestion.\n",
       "* CUBIC considers packet loss, delay, and jitter as signals for congestion and aims to fill up link bandwidth without queuing.\n",
       "* BBR interprets network \"signals\" as the bottleneck bandwidth and RTT, aiming to match the sending rate with the bandwidth-delay product.\n",
       "\n",
       "These differences in design philosophies lead to distinct behaviors and performance characteristics of each algorithm in different network conditions."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "query = \"How do the design philosophies of BBR, CUBIC, and NewReno differ in their interpretation of network 'signals'?\"\n",
    "pose(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3d59d090-19b6-4be7-a8c5-15f20ff4d9b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Why does TCP Vegas perform poorly in LEO satellite networks compared to BBR?"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Retrieved documents:\n",
      "comparative_study.pdf\n",
      "comparative_study.pdf\n",
      "comparative_study.pdf\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "According to the text, TCP Vegas detects congestion by delay increase, which can lead to low throughput because it is sensitive to network delays. In LEO satellite networks, the frequent handovers and varying link delays due to satellite movement can cause TCP Vegas to incorrectly identify these changes as congestion, leading to poor performance.\n",
       "\n",
       "In contrast, BBR (Bottleneck Bandwidth and Round-trip time) shows more resilient behavior in LEO satellite networks because it frequently probes the network bandwidth and RTT, allowing it to adapt to changing conditions. This enables BBR to achieve a good balance between throughput and latency, even in the face of frequent path changes and delay variations caused by satellite movement.\n",
       "\n",
       "It's worth noting that the poor performance of TCP Vegas is not unique to LEO satellite networks. The text mentions that this sensitivity to network delays can lead to low throughput in other environments as well."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "query = \"Why does TCP Vegas perform poorly in LEO satellite networks compared to BBR?\"\n",
    "pose(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2b886af2-6136-48cc-bc95-387a3d178d5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Compare how TCP CUBIC and TCP Hybla address the problem of 'RTT Unfairness.'"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Retrieved documents:\n",
      "CUBIC-checkpoint.pdf\n",
      "CUBIC.pdf\n",
      "Hybla.pdf\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "TCP CUBIC and TCP Hybla are two variants of the Transmission Control Protocol (TCP) that aim to address the issue of \"RTT Unfairness.\" RTT Unfairness occurs when connections with different round-trip times (RTTs) compete for bandwidth on a shared link, leading to unfair allocation of resources.\n",
       "\n",
       "**TCP CUBIC**\n",
       "\n",
       "TCP CUBIC is designed to mitigate RTT Unfairness by adjusting the congestion window growth rate based on the observed RTT. When the RTT increases, TCP CUBIC reduces the congestion window growth rate to prevent the connection from consuming too much bandwidth. This approach helps to ensure that connections with longer RTTs do not starve those with shorter RTTs.\n",
       "\n",
       "**TCP Hybla**\n",
       "\n",
       "TCP Hybla takes a different approach to addressing RTT Unfairness. It uses a dynamic adjustment of the slow-start threshold (ssthresh) based on the observed RTT. When the RTT increases, TCP Hybla reduces the ssthresh, which in turn limits the congestion window growth rate. This approach helps to prevent connections with longer RTTs from consuming too much bandwidth and starving those with shorter RTTs.\n",
       "\n",
       "**Comparison**\n",
       "\n",
       "Both TCP CUBIC and TCP Hybla aim to address RTT Unfairness by adjusting the congestion window growth rate or slow-start threshold based on the observed RTT. However, they differ in their approach:\n",
       "\n",
       "* TCP CUBIC adjusts the congestion window growth rate directly.\n",
       "* TCP Hybla adjusts the slow-start threshold.\n",
       "\n",
       "In terms of fairness and friendliness, both protocols aim to ensure that connections with different RTTs share the bandwidth fairly. However, TCP Hybla is designed to be more friendly to wireless connections, which often have longer RTTs due to the inherent delay introduced by wireless channels.\n",
       "\n",
       "**Packet spacing**\n",
       "\n",
       "TCP Hybla also introduces a packet spacing mechanism to reduce burstiness and improve fairness in networks with heterogeneous RTTs. This feature helps to spread out the transmission of packets over the RTT, reducing the likelihood of congestion and improving overall network performance.\n",
       "\n",
       "In summary, while both TCP CUBIC and TCP Hybla address the issue of RTT Unfairness, they differ in their approach and design. TCP Hybla is designed to be more friendly to wireless connections and introduces a packet spacing mechanism to improve fairness and reduce burstiness."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "query = \"Compare how TCP CUBIC and TCP Hybla address the problem of 'RTT Unfairness.'\"\n",
    "pose(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "8b47f5c2-a5f8-4e7a-a8a8-9ba7d709277f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "What is the significance of the 'recover' variable and 'Partial ACKs' in the NewReno algorithm?"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Retrieved documents:\n",
      "NewReno.pdf\n",
      "NewReno.pdf\n",
      "NewReno.pdf\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "The `recover` variable and partial acknowledgments play crucial roles in the NewReno algorithm for handling multiple packet losses during Fast Recovery.\n",
       "\n",
       "**`recover` Variable:**\n",
       "\n",
       "* The `recover` variable is initialized with the initial send sequence number.\n",
       "* When three duplicate ACKs are received, the sender checks if the Cumulative Acknowledgement field covers more than the current value of `recover`. If it does, the algorithm proceeds to Step 1A (Invoking Fast Retransmit). Otherwise, it goes to Step 1B (Not invoking Fast Retransmit).\n",
       "* During Fast Recovery, the highest sequence number transmitted is recorded in the `recover` variable.\n",
       "* The `recover` variable serves as a threshold for determining whether a new packet loss has occurred. If an ACK arrives that acknowledges data up to and including the current value of `recover`, it indicates that all packets sent since the beginning of Fast Recovery have been received by the receiver, except for one (the next in-sequence packet).\n",
       "\n",
       "**Partial Acknowledgments:**\n",
       "\n",
       "* A partial acknowledgment is an ACK that acknowledges some but not all of the packets transmitted before entering Fast Retransmit.\n",
       "* When a partial acknowledgment is received during Fast Recovery, the sender infers that the next in-sequence packet has been lost and retransmits it (Step 5).\n",
       "* The `recover` variable helps determine whether the ACK is a partial acknowledgment or an acknowledgement for all packets sent since the beginning of Fast Recovery.\n",
       "\n",
       "In summary, the `recover` variable and partial acknowledgments are essential components of the NewReno algorithm. They enable the sender to:\n",
       "\n",
       "1. Determine when to invoke Fast Retransmit (Step 1A).\n",
       "2. Record the highest sequence number transmitted during Fast Recovery.\n",
       "3. Identify whether an ACK is a partial acknowledgment or an acknowledgement for all packets sent since the beginning of Fast Recovery.\n",
       "\n",
       "By using these components, NewReno can more effectively handle multiple packet losses during Fast Recovery and improve network performance in scenarios where SACK is not available."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "query = \"What is the significance of the 'recover' variable and 'Partial ACKs' in the NewReno algorithm?\"\n",
    "pose(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "4094c912-ade1-46e4-b38c-9ca344f2f80a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Explain the sequential relationship between BBR’s 'Startup' and 'Drain' states."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Retrieved documents:\n",
      "BBR.pdf\n",
      "BBR.pdf\n",
      "BBR.pdf\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "According to the text, the sequential relationship between BBR's 'Startup' and 'Drain' states is as follows:\n",
       "\n",
       "1. The connection starts in the 'Startup' state, where it rapidly probes for bandwidth using a pacing_gain of 5/4.\n",
       "2. If the startup phase is successful (i.e., the connection reaches high throughput), the connection transitions to the 'Drain' state.\n",
       "3. In the 'Drain' state, the connection drains any resulting queue by reducing its pacing_gain to 1/4 for a short period of time (typically one RTprop).\n",
       "4. After draining the queue, the connection leaves the 'Drain' state and enters either the 'ProbeBW' or 'Startup' states, depending on whether it estimates that the pipe was filled already.\n",
       "\n",
       "So, in summary, the 'Drain' state is a transitional state between the 'Startup' and 'ProbeBW' states, where the connection drains any queue that may have built up during the startup phase."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "query = \"Explain the sequential relationship between BBR’s 'Startup' and 'Drain' states.\"\n",
    "pose(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "787c6bd1-9621-49eb-8043-90a1de61f179",
   "metadata": {},
   "source": [
    "___\n",
    "\n",
    "How do we know that these answers are coming from the documents or are from the model's pre-trained knowledge? This takes a bit of prompt engineering. Let's try editing the system message:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f882b0df-1e0d-4c68-961e-e04dfd85448c",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dynamic_prompt\n",
    "def prompt_with_context(request: ModelRequest) -> str:\n",
    "    \"\"\"Inject context into state messages.\"\"\"\n",
    "    last_query = request.state[\"messages\"][-1].text\n",
    "    retrieved_docs = vector_store.similarity_search(last_query, k=3)\n",
    "\n",
    "    docs_content = \"\\n\\n\".join(doc.page_content for doc in retrieved_docs)\n",
    "\n",
    "    # Print documents used:\n",
    "    print(\"\\nRetrieved documents:\") ##\n",
    "    for doc in retrieved_docs: ##\n",
    "        print(doc.metadata[\"source\"]) ##\n",
    "    print()\n",
    "\n",
    "    system_message = (\n",
    "        # Edit here:\n",
    "        \"You are a helpful assistant. Answer only using the information from the following documents.\"\n",
    "        f\"\\n\\n{docs_content}\"\n",
    "    )\n",
    "\n",
    "    return system_message\n",
    "\n",
    "\n",
    "agent = create_agent(llm, tools=[], middleware=[prompt_with_context])\n",
    "\n",
    "def pose(query):\n",
    "    for step in agent.stream(\n",
    "        {\"messages\": [{\"role\": \"user\", \"content\": query}]},\n",
    "        stream_mode=\"values\",\n",
    "    ):\n",
    "        display(Markdown(step[\"messages\"][-1].text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "04a09893-a6aa-4c53-8b2b-aadd49a103e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Who was the fifth president of the United States?"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Retrieved documents:\n",
      "BBR.pdf\n",
      "NewReno.pdf\n",
      "comparative_study.pdf\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "The text doesn't mention the fifth president of the United States. It appears to be a research paper about congestion control schemes for LEO (Low Earth Orbit) satellite networks and their performance compared to traditional terrestrial networks. If you're looking for information on U.S. presidents, I'd be happy to help with that!"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "query = \"Who was the fifth president of the United States?\"\n",
    "pose(query)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag_ollama",
   "language": "python",
   "name": "rag_ollama"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
